{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit_card_exp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/credit_card_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGuRPcn_IsKD"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNizIZXIrdM"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_w-5Z0sMsJ"
      },
      "source": [
        "## Credit Card Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXiM3pnF5j-2"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "# data = df.to_numpy()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHo1NiB4xWr"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate')\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData,df.iloc[:,-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kzCB3F5uWL"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyg90-iG5vCB"
      },
      "source": [
        "NewF1 = newfeature(df.V3, df.V7)\r\n",
        "NewF2 = newfeature(df.V11, df.V12)\r\n",
        "NewF3 = newfeature(df.V12, df.V16)\r\n",
        "NewF4 = newfeature(df.V16, df.V17)\r\n",
        "NewF5 = newfeature(df.V16, df.V18)\r\n",
        "NewF6 = newfeature(df.V17, df.V18)\r\n",
        "# new feature\r\n",
        "NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMYL_506R_G"
      },
      "source": [
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df.iloc[:,-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrl86Dhy9jy"
      },
      "source": [
        "# sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.learning_rate = learning_rate\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "  \n",
        "  # training\n",
        "  def fit(self):\n",
        "    n,m = np.shape(self.X_train)\n",
        "    itrnum = 500       # max number of iterations \n",
        "    W = np.ones([m+1,itrnum+1]) # weights, initialized with 1 ---> change to 1 column\n",
        "    e = 0.01        # iteration stop criteria\n",
        "    der = 0        # derivative\n",
        "    for k in range(0,itrnum):\n",
        "      for i in range(0,n):\n",
        "        xi = self.X_train[i].T\n",
        "        x0 = np.array([1])\n",
        "        xi = np.concatenate((xi, x0),axis = 0)\n",
        "        yi = self.y_train[i]\n",
        "        der = der-xi*(yi-sigmoid(np.matmul(W[:,k].T,xi))) # take derivative w.r.t W\n",
        "      W[:,k+1] = W[:,k]-self.learning_rate*der       # update rule\n",
        "      if (np.linalg.norm(W[:,k+1]-W[:,k]))**2<e:         \n",
        "        break \n",
        "    return W[:,k+1]\n",
        "  \n",
        "  # validation\n",
        "  def predict(self):\n",
        "    w = self.fit()\n",
        "    n,m = np.shape(self.X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      xi = self.X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      #p0=1-sigmoid(np.matmul(w.T,xi))\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self):\n",
        "    y_predict = self.predict()\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    # print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accuracies = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "    \n",
        "      train_only = Logistic_regression(X_train, y_train, lr, X_test, y_test)\n",
        "      train_and_test = Logistic_regression(X_train, y_train, lr, X_test, y_test)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "      accuracy = logistic_regression.Accu_eval()\n",
        "      accuracies.append(accuracy)\n",
        "    return np.mean(accuracies)\n",
        "      # this will print the evaluation results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459b9879-adaf-4909-e0e1-8c72b7ae9141"
      },
      "source": [
        "lrs = np.logspace(-6, -1, 6) # different learning rates to try\n",
        "# or we can also try other hyperparameters here\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "for lr in lrs:\n",
        "  print(\"----------LEARNING RATE: \", lr, \"----------\")\n",
        "  accu_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"----------AVERAGE ACCURACY\", accu_avg, \"----------\")\n",
        "  print(\"\\n---------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------LEARNING RATE:  1e-06 ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.26515151515151514\n",
            "precision: 0.34551495016611294\n",
            "recall: 0.5252525252525253\n",
            "F: 0.4168336673346693\n",
            "\n",
            "accuracy: 0.23115577889447236\n",
            "precision: 0.30344827586206896\n",
            "recall: 0.4583333333333333\n",
            "F: 0.3651452282157676\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.2572509457755359\n",
            "precision: 0.33668341708542715\n",
            "recall: 0.5101522842639594\n",
            "F: 0.4056508577194753\n",
            "\n",
            "accuracy: 0.26262626262626265\n",
            "precision: 0.34\n",
            "recall: 0.5204081632653061\n",
            "F: 0.41129032258064513\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.2572509457755359\n",
            "precision: 0.33444816053511706\n",
            "recall: 0.5115089514066496\n",
            "F: 0.4044489383215369\n",
            "\n",
            "accuracy: 0.26262626262626265\n",
            "precision: 0.348993288590604\n",
            "recall: 0.5148514851485149\n",
            "F: 0.41600000000000004\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.2597730138713745\n",
            "precision: 0.3383333333333333\n",
            "recall: 0.5165394402035624\n",
            "F: 0.40886203423967776\n",
            "\n",
            "accuracy: 0.25252525252525254\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.494949494949495\n",
            "F: 0.3983739837398374\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.25220680958385877\n",
            "precision: 0.3316412859560068\n",
            "recall: 0.49746192893401014\n",
            "F: 0.3979695431472081\n",
            "\n",
            "accuracy: 0.2828282828282828\n",
            "precision: 0.358974358974359\n",
            "recall: 0.5714285714285714\n",
            "F: 0.4409448818897638\n",
            "\n",
            "----------ACCURACY ON TRAINING SET:  0.258326646031564 ----------\n",
            "----------ACCURACY ON VALIDATION SET:  0.2583523679001066 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  1e-05 ----------\n",
            "----------FOLD  1 ----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9318181818181818\n",
            "precision: 0.9776536312849162\n",
            "recall: 0.8838383838383839\n",
            "F: 0.9283819628647215\n",
            "\n",
            "accuracy: 0.9195979899497487\n",
            "precision: 0.9651162790697675\n",
            "recall: 0.8645833333333334\n",
            "F: 0.9120879120879122\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9382093316519546\n",
            "precision: 0.9116945107398569\n",
            "recall: 0.9695431472081218\n",
            "F: 0.9397293972939729\n",
            "\n",
            "accuracy: 0.9242424242424242\n",
            "precision: 0.9108910891089109\n",
            "recall: 0.9387755102040817\n",
            "F: 0.9246231155778896\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9432534678436317\n",
            "precision: 0.9752747252747253\n",
            "recall: 0.907928388746803\n",
            "F: 0.9403973509933775\n",
            "\n",
            "accuracy: 0.9343434343434344\n",
            "precision: 0.9583333333333334\n",
            "recall: 0.9108910891089109\n",
            "F: 0.934010152284264\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9104665825977302\n",
            "precision: 0.865909090909091\n",
            "recall: 0.9694656488549618\n",
            "F: 0.9147659063625451\n",
            "\n",
            "accuracy: 0.8939393939393939\n",
            "precision: 0.8421052631578947\n",
            "recall: 0.9696969696969697\n",
            "F: 0.9014084507042254\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9344262295081968\n",
            "precision: 0.9723756906077348\n",
            "recall: 0.8934010152284264\n",
            "F: 0.9312169312169312\n",
            "\n",
            "accuracy: 0.9494949494949495\n",
            "precision: 0.9782608695652174\n",
            "recall: 0.9183673469387755\n",
            "F: 0.9473684210526316\n",
            "\n",
            "----------ACCURACY ON TRAINING SET:  0.931634758683939 ----------\n",
            "----------ACCURACY ON VALIDATION SET:  0.9243236383939901 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.0001 ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9330808080808081\n",
            "precision: 0.9777158774373259\n",
            "recall: 0.8863636363636364\n",
            "F: 0.9298013245033112\n",
            "\n",
            "accuracy: 0.9246231155778895\n",
            "precision: 0.9655172413793104\n",
            "recall: 0.875\n",
            "F: 0.9180327868852458\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9041614123581336\n",
            "precision: 0.8502202643171806\n",
            "recall: 0.9796954314720813\n",
            "F: 0.9103773584905659\n",
            "\n",
            "accuracy: 0.8484848484848485\n",
            "precision: 0.7931034482758621\n",
            "recall: 0.9387755102040817\n",
            "F: 0.8598130841121495\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9394703656998739\n",
            "precision: 0.9750692520775623\n",
            "recall: 0.9002557544757033\n",
            "F: 0.9361702127659575\n",
            "\n",
            "accuracy: 0.9343434343434344\n",
            "precision: 0.9583333333333334\n",
            "recall: 0.9108910891089109\n",
            "F: 0.934010152284264\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9495586380832283\n",
            "precision: 0.9757412398921833\n",
            "recall: 0.9211195928753181\n",
            "F: 0.9476439790575917\n",
            "\n",
            "accuracy: 0.9444444444444444\n",
            "precision: 0.9583333333333334\n",
            "recall: 0.9292929292929293\n",
            "F: 0.9435897435897437\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9419924337957125\n",
            "precision: 0.9243902439024391\n",
            "recall: 0.9619289340101523\n",
            "F: 0.9427860696517414\n",
            "\n",
            "accuracy: 0.9696969696969697\n",
            "precision: 0.96\n",
            "recall: 0.9795918367346939\n",
            "F: 0.9696969696969697\n",
            "\n",
            "----------ACCURACY ON TRAINING SET:  0.9336527316035512 ----------\n",
            "----------ACCURACY ON VALIDATION SET:  0.9243185625095173 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.001 ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9507575757575758\n",
            "precision: 0.9785522788203753\n",
            "recall: 0.9217171717171717\n",
            "F: 0.9492847854356307\n",
            "\n",
            "accuracy: 0.9296482412060302\n",
            "precision: 0.9659090909090909\n",
            "recall: 0.8854166666666666\n",
            "F: 0.9239130434782609\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9546027742749055\n",
            "precision: 0.9661458333333334\n",
            "recall: 0.9416243654822335\n",
            "F: 0.9537275064267352\n",
            "\n",
            "accuracy: 0.9545454545454546\n",
            "precision: 0.978494623655914\n",
            "recall: 0.9285714285714286\n",
            "F: 0.9528795811518325\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.8915510718789408\n",
            "precision: 0.8381374722838137\n",
            "recall: 0.9667519181585678\n",
            "F: 0.8978622327790974\n",
            "\n",
            "accuracy: 0.9090909090909091\n",
            "precision: 0.8547008547008547\n",
            "recall: 0.9900990099009901\n",
            "F: 0.9174311926605504\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9369482976040353\n",
            "precision: 0.9803921568627451\n",
            "recall: 0.8905852417302799\n",
            "F: 0.9333333333333333\n",
            "\n",
            "accuracy: 0.9141414141414141\n",
            "precision: 0.9659090909090909\n",
            "recall: 0.8585858585858586\n",
            "F: 0.9090909090909091\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9394703656998739\n",
            "precision: 0.970108695652174\n",
            "recall: 0.9060913705583756\n",
            "F: 0.937007874015748\n",
            "\n",
            "accuracy: 0.9545454545454546\n",
            "precision: 0.978494623655914\n",
            "recall: 0.9285714285714286\n",
            "F: 0.9528795811518325\n",
            "\n",
            "----------ACCURACY ON TRAINING SET:  0.9346660170430662 ----------\n",
            "----------ACCURACY ON VALIDATION SET:  0.9323942947058527 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.01 ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9330808080808081\n",
            "precision: 0.9777158774373259\n",
            "recall: 0.8863636363636364\n",
            "F: 0.9298013245033112\n",
            "\n",
            "accuracy: 0.9195979899497487\n",
            "precision: 0.9651162790697675\n",
            "recall: 0.8645833333333334\n",
            "F: 0.9120879120879122\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.8839848675914249\n",
            "precision: 0.8226495726495726\n",
            "recall: 0.9771573604060914\n",
            "F: 0.8932714617169373\n",
            "\n",
            "accuracy: 0.8080808080808081\n",
            "precision: 0.7419354838709677\n",
            "recall: 0.9387755102040817\n",
            "F: 0.828828828828829\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9445145018915511\n",
            "precision: 0.9753424657534246\n",
            "recall: 0.9104859335038363\n",
            "F: 0.9417989417989417\n",
            "\n",
            "accuracy: 0.9343434343434344\n",
            "precision: 0.9583333333333334\n",
            "recall: 0.9108910891089109\n",
            "F: 0.934010152284264\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9407313997477932\n",
            "precision: 0.9158653846153846\n",
            "recall: 0.9694656488549618\n",
            "F: 0.9419035846724351\n",
            "\n",
            "accuracy: 0.9141414141414141\n",
            "precision: 0.8727272727272727\n",
            "recall: 0.9696969696969697\n",
            "F: 0.9186602870813397\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9495586380832283\n",
            "precision: 0.9657894736842105\n",
            "recall: 0.9314720812182741\n",
            "F: 0.9483204134366925\n",
            "\n",
            "accuracy: 0.9646464646464646\n",
            "precision: 0.9690721649484536\n",
            "recall: 0.9591836734693877\n",
            "F: 0.964102564102564\n",
            "\n",
            "----------ACCURACY ON TRAINING SET:  0.9303740430789611 ----------\n",
            "----------ACCURACY ON VALIDATION SET:  0.9081620222323739 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.1 ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9570707070707071\n",
            "precision: 0.9788359788359788\n",
            "recall: 0.9343434343434344\n",
            "F: 0.9560723514211885\n",
            "\n",
            "accuracy: 0.9396984924623115\n",
            "precision: 0.9666666666666667\n",
            "recall: 0.90625\n",
            "F: 0.9354838709677419\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9155107187894073\n",
            "precision: 0.8674157303370786\n",
            "recall: 0.9796954314720813\n",
            "F: 0.9201430274135877\n",
            "\n",
            "accuracy: 0.8686868686868687\n",
            "precision: 0.8214285714285714\n",
            "recall: 0.9387755102040817\n",
            "F: 0.8761904761904763\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9382093316519546\n",
            "precision: 0.975\n",
            "recall: 0.8976982097186701\n",
            "F: 0.9347536617842876\n",
            "\n",
            "accuracy: 0.9292929292929293\n",
            "precision: 0.967741935483871\n",
            "recall: 0.8910891089108911\n",
            "F: 0.9278350515463919\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9432534678436317\n",
            "precision: 0.9728260869565217\n",
            "recall: 0.910941475826972\n",
            "F: 0.9408672798948752\n",
            "\n",
            "accuracy: 0.9292929292929293\n",
            "precision: 0.956989247311828\n",
            "recall: 0.898989898989899\n",
            "F: 0.9270833333333334\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9470365699873896\n",
            "precision: 0.9731182795698925\n",
            "recall: 0.9187817258883249\n",
            "F: 0.9451697127937337\n",
            "\n",
            "accuracy: 0.9595959595959596\n",
            "precision: 0.96875\n",
            "recall: 0.9489795918367347\n",
            "F: 0.9587628865979382\n",
            "\n",
            "----------ACCURACY ON TRAINING SET:  0.940216159068618 ----------\n",
            "----------ACCURACY ON VALIDATION SET:  0.9253134358661995 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tX0BHqIfsy"
      },
      "source": [
        "## Experiment with different features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eabae67-cfaa-4f09-c702-2b985047de7e"
      },
      "source": [
        "lr = 0.001\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n",
            "----------FOLD  1 ----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8548387096774194\n",
            "precision: 0.75\n",
            "recall: 0.7894736842105263\n",
            "F: 0.7692307692307692\n",
            "specificity: 0.8837209302325582\n",
            "False Positive Rate: 0.11627906976744186\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.8548387096774194\n",
            "precision: 0.7368421052631579\n",
            "recall: 0.7777777777777778\n",
            "F: 0.7567567567567567\n",
            "specificity: 0.8863636363636364\n",
            "False Positive Rate: 0.11363636363636363\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.8064516129032258\n",
            "precision: 0.8\n",
            "recall: 0.5714285714285714\n",
            "F: 0.6666666666666666\n",
            "specificity: 0.926829268292683\n",
            "False Positive Rate: 0.07317073170731707\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.8709677419354839\n",
            "precision: 0.9047619047619048\n",
            "recall: 0.76\n",
            "F: 0.8260869565217391\n",
            "specificity: 0.9459459459459459\n",
            "False Positive Rate: 0.05405405405405406\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9516129032258065\n",
            "precision: 0.8421052631578947\n",
            "recall: 1.0\n",
            "F: 0.9142857142857143\n",
            "specificity: 0.9347826086956522\n",
            "False Positive Rate: 0.06521739130434782\n",
            "\n",
            "----------AVERAGE ACCURACY 0.867741935483871 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b48612-371c-40f8-bb85-7b341d8a8c95"
      },
      "source": [
        "lr = 0.001\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "----------FOLD  1 ----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8548387096774194\n",
            "precision: 0.9285714285714286\n",
            "recall: 0.6190476190476191\n",
            "F: 0.742857142857143\n",
            "specificity: 0.975609756097561\n",
            "False Positive Rate: 0.024390243902439025\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.8387096774193549\n",
            "precision: 0.5555555555555556\n",
            "recall: 0.8333333333333334\n",
            "F: 0.6666666666666667\n",
            "specificity: 0.84\n",
            "False Positive Rate: 0.16\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.8387096774193549\n",
            "precision: 0.7666666666666667\n",
            "recall: 0.8846153846153846\n",
            "F: 0.8214285714285715\n",
            "specificity: 0.8055555555555556\n",
            "False Positive Rate: 0.19444444444444445\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.8225806451612904\n",
            "precision: 0.7\n",
            "recall: 0.7368421052631579\n",
            "F: 0.717948717948718\n",
            "specificity: 0.8604651162790697\n",
            "False Positive Rate: 0.13953488372093023\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.7419354838709677\n",
            "precision: 0.6470588235294118\n",
            "recall: 0.5238095238095238\n",
            "F: 0.5789473684210527\n",
            "specificity: 0.8536585365853658\n",
            "False Positive Rate: 0.14634146341463414\n",
            "\n",
            "----------AVERAGE ACCURACY 0.8193548387096774 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}