{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patients_new_fit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/Patients_new_fit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NkwhApnnJk"
      },
      "source": [
        "# ECSE 551 Mini-project 1\n",
        "*Group 10: Junhao Wang, Yinan Zhou, and Ruilin Ji*\n",
        "\n",
        "This notebook is dedicated for the **Orthopedic patients dataset**, including the model, cross validation, and various experiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3nM6IIOBf0A"
      },
      "source": [
        "## Start here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oskj54Fv8eGB",
        "outputId": "9a36c50b-3a78-4642-91d6-4dba1a74315e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33518e2e-bba2-4953-c644-344eb17341d5"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFoqVsWOP14"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1gREIMPzw7M"
      },
      "source": [
        "## Orthopedic Patients Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc7bhCtyW17b"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('orthopedic_patients.csv')\n",
        "original_data = df.to_numpy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybt1JT3h0JpU"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate')\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData, df['Class']))\r\n",
        "# np.savetxt('normalized_orthopedic_patients.csv', NorPatientData, delimiter=',')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oDHjN7u0rbT"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHfVd9v2elN"
      },
      "source": [
        "# new feature\r\n",
        "NewF1 = newfeature(df.pelvic_incidence, df.sacral_slope) # new feature by multiplying two high-correlation feature\r\n",
        "NewF2 = df.iloc[:,0]             # initialize new feature 2 using 1st feature\r\n",
        "n_row = np.shape(original_data)[0]\r\n",
        "NewF = np.zeros(n_row)            # initialize new features using 0s\r\n",
        "for col in range(6):\r\n",
        "  # new feature 2: multiplying all features\r\n",
        "  if col>0:\r\n",
        "    NewF2 = newfeature(NewF2,df.iloc[:,col])\r\n",
        "  # new feature 3-8: square all columns\r\n",
        "  new = newfeature(df.iloc[:,col],df.iloc[:,col]) # square feature\r\n",
        "  NewF = np.column_stack((NewF,new))\r\n",
        "\r\n",
        "NewF = np.delete(NewF,0,1)\r\n",
        "# print(NewF2)\r\n",
        "# print(np.shape(NewF))\r\n",
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF1,NewF2,NewF,df['Class']))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrl86Dhy9jy"
      },
      "source": [
        "# sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self):#,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    pass\n",
        "    \n",
        "  # training\n",
        "  def fit(self, X_train, y_train, learning_rate):\n",
        "    n, m = np.shape(X_train)  # n samples, m features\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    w = np.ones([m+1, 1]) # features + 1\n",
        "    dummy_feature = np.ones([n, 1])\n",
        "    X = np.concatenate((X_train, dummy_feature), axis=1) # n samples, m+1 features\n",
        "    # max iteration allowed\n",
        "    max_iter = 5000 \n",
        "    for i in range(max_iter):\n",
        "      y_predict = sigmoid(np.matmul(X, w))  # n * 1\n",
        "      grad = -np.matmul(X.T, (y_train - y_predict))  # m+1 * 1\n",
        "      w = w - learning_rate * grad\n",
        "      if np.linalg.norm(learning_rate * grad) < 0.001:\n",
        "        print(\"Early stop at iteration: \", i+1)\n",
        "        break\n",
        "    return w\n",
        "  \n",
        "  # validation\n",
        "  def predict(self,w,X_test):\n",
        "    #n,m = np.shape(self.X_test)\n",
        "    n,m = np.shape(X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      #xi = self.X_test[i].T\n",
        "      xi = X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self,y_test,y_predict):\n",
        "    #y_predict = self.predict(X_test)\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    '''for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1'''\n",
        "    for i in range(n):\n",
        "      if  y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1    \n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    # precision = TP/(TP+FP)\n",
        "    # recall = TP/(TP+FN)\n",
        "    # F = 2*precision*recall/(precision+recall)\n",
        "    # specificity = TN/(FP+TN)\n",
        "    # FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3ZNHiUUXTq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13128e3-ecd3-45e5-c60f-a9b1239138c4"
      },
      "source": [
        "# figure out which feature is of the most importance\r\n",
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels\r\n",
        "w = model.fit(X,y,learning_rate=0.001)\r\n",
        "print(w)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  1337\n",
            "[[ 0.12868317]\n",
            " [-0.77648809]\n",
            " [ 0.23400975]\n",
            " [ 1.20541102]\n",
            " [ 1.34390655]\n",
            " [-5.68958047]\n",
            " [-2.90097301]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accu_trains = []\n",
        "    accu_tests = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      model = Logistic_regression()\n",
        "      w = model.fit(X_train, y_train, lr)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "\n",
        "      print(\"----Train----\")\n",
        "      y_predict_train = model.predict(w, X_train)\n",
        "      accu_train = model.Accu_eval(y_train, y_predict_train)\n",
        "      accu_trains.append(accu_train)\n",
        "\n",
        "      print(\"----Validation----\")\n",
        "      y_predict_test = model.predict(w, X_test)\n",
        "      accu_test = model.Accu_eval(y_test, y_predict_test)\n",
        "      accu_tests.append(accu_test)\n",
        "\n",
        "    return np.mean(accu_trains), np.mean(accu_tests)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx0mwWWwXuMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0de46c-e2d4-4c94-f120-f7e140e421db"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7706093189964157\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7706093189964157\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7598566308243727\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7799283154121863 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7548387096774194 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8028673835125448\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7598566308243727\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7813620071684587 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7451612903225807 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6451612903225806\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7706093189964157\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8028673835125448\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7526881720430108\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.778136200716846 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7645161290322581 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7598566308243727\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7526881720430108\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7347670250896058\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7720430107526882 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7483870967741936 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7992831541218638\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7311827956989247\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7738351254480287 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7903225806451613 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7706093189964157\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7598566308243727\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9032258064516129\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7853046594982078 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7709677419354839 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7526881720430108\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6451612903225806\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.7383512544802867\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8028673835125448\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7598566308243727\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7706093189964158 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.767741935483871 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8243727598566308\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7455197132616488\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7347670250896058\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7817204301075269 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.767741935483871 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7706093189964157\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7827956989247312 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7935483870967742 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.7634408602150538\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.7992831541218638\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8028673835125448\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7777777777777778\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9032258064516129\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.786021505376344 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7935483870967742 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trLpB7VY62VB",
        "outputId": "f1dc5da2-8348-4c0a-b527-f0a565876e2f"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "Early stop at iteration:  1242\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.6236559139784946\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.4838709677419355\n",
            "\n",
            "Early stop at iteration:  1254\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.6057347670250897\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "Early stop at iteration:  1245\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.6308243727598566\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6451612903225806\n",
            "\n",
            "Early stop at iteration:  1242\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.6344086021505376\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6451612903225806\n",
            "\n",
            "Early stop at iteration:  1255\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.6057347670250897\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.5806451612903226\n",
            "\n",
            "Early stop at iteration:  1235\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.6057347670250897\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6451612903225806\n",
            "\n",
            "Early stop at iteration:  1254\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.6200716845878136\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3225806451612903\n",
            "\n",
            "Early stop at iteration:  1279\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.6200716845878136\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "Early stop at iteration:  1257\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.6236559139784946\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.5806451612903226\n",
            "\n",
            "Early stop at iteration:  1281\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.6308243727598566\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.6200716845878136 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.6096774193548387 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "Early stop at iteration:  973\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "Early stop at iteration:  954\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  967\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  969\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8028673835125448\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  992\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7956989247311828\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  969\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1023\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7992831541218638\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  997\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  985\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "Early stop at iteration:  977\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8057347670250895 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7935483870967742 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "Early stop at iteration:  1217\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "Early stop at iteration:  1291\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8530465949820788\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.967741935483871\n",
            "\n",
            "Early stop at iteration:  1278\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8781362007168458\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1338\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8781362007168458\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1371\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1339\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8494623655913979\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1303\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1377\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1322\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8745519713261649\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  1271\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8666666666666666 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8580645161290322 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "Early stop at iteration:  1869\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  1763\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8458781362007168\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "Early stop at iteration:  1831\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1874\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1933\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  1816\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1813\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8745519713261649\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1887\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  1843\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1858\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8645161290322582 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8451612903225806 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "Early stop at iteration:  1703\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  1549\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8494623655913979\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "Early stop at iteration:  1687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1670\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1723\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  1601\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1616\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1700\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1643\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1697\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8627240143369177 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8516129032258064 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "Early stop at iteration:  1157\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  1034\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8494623655913979\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "Early stop at iteration:  1171\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1133\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1161\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  1070\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1089\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1165\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  1108\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  1166\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8620071684587813 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8516129032258064 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "Early stop at iteration:  649\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  574\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8530465949820788\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "Early stop at iteration:  668\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  637\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  648\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  594\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  608\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  658\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  619\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  659\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8630824372759858 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8516129032258064 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "Early stop at iteration:  322\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "Early stop at iteration:  283\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8530465949820788\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "Early stop at iteration:  335\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  317\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  321\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  301\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  329\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  307\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "Early stop at iteration:  329\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8623655913978494 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8516129032258064 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8207885304659498\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8243727598566308\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8422939068100358\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8207885304659498\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8243727598566308\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8315412186379928\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8261648745519713 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8161290322580644 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8172043010752689\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8315412186379928\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8172043010752689\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8315412186379928\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8207885304659498\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8186379928315413 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8064516129032258 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTvS3gB7C-_Y"
      },
      "source": [
        "## Experiment with different features\n",
        "\n",
        "During the experiment on different learning rates, we found that the best learning rate is **0.0129**, so we use this learning rate for our experiment with different feature selections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f651874-28aa-42bc-da4f-b7a55a8072a8"
      },
      "source": [
        "lr = 0.0129\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n",
            "Early stop at iteration:  292\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  315\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  317\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  295\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "Early stop at iteration:  326\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  274\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8530465949820788\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.967741935483871\n",
            "\n",
            "Early stop at iteration:  332\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  345\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "Early stop at iteration:  285\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "Early stop at iteration:  347\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8673835125448028\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------AVERAGE ACCURACY 0.8516129032258064 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8SIJKiY5YX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd587d0-d118-4e8f-ba51-8ba2d60b4041"
      },
      "source": [
        "lr = 0.0129\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.7706093189964157\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7455197132616488\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7849462365591398\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7813620071684588\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6451612903225806\n",
            "\n",
            "----------AVERAGE ACCURACY 0.7387096774193549 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d16a1a-543b-4cc1-8ebd-fb75c2e40444"
      },
      "source": [
        "lr = 0.0129\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\", accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8566308243727598\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8853046594982079\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8781362007168458\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8637992831541219\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.967741935483871\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8745519713261649\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8888888888888888\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8745519713261649\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8602150537634409\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9354838709677419\n",
            "\n",
            "----------AVERAGE ACCURACY: train- 0.8713261648745518  vs. validation- 0.8548387096774193 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSYRgbudHMP"
      },
      "source": [
        "## Measure the run time\n",
        "See whether the model converges faster on normalized data than on original data. This is measured by training the model and time it. This part stands on its own, and is not related to any of the above process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhONMhAxkuC7"
      },
      "source": [
        "###Using the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T-jHRpsdgHZ"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(original_data)\n",
        "X = original_data[:, :-1]  # features\n",
        "y = original_data[:, -1]   # labels"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKriES7le0Pz",
        "outputId": "a4ff14a0-19f6-4116-ede9-0c95365422a2"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.00001)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 141 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ39ltUkkZJj",
        "outputId": "ba91f102-06f1-4f53-d6a3-b16d1a4d3885"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 168 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoZ_UQERkn5U",
        "outputId": "2232f27d-c08d-4110-8678-94abff941861"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.01)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 164 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCwwb-clC5m"
      },
      "source": [
        "###Using normalized dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOcmreeith4"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrPg4E1ti1iV",
        "outputId": "4a584153-832a-4518-eead-93b8432cb1db"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.00001)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "Early stop at iteration:  1216\n",
            "10 loops, best of 3: 60.9 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oePKiDuLlyNs",
        "outputId": "ed866183-e4f1-45a0-e5c5-794610b3c1b2"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "Early stop at iteration:  1337\n",
            "10 loops, best of 3: 66 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44s_vMSPlyNs",
        "outputId": "6a6527f4-58b2-452e-e1d7-a7fceece2d7b"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.01)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "Early stop at iteration:  344\n",
            "100 loops, best of 3: 19 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJsJ2VaR7k0K"
      },
      "source": [
        "###Scan through more lrs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKC_xyrBEdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db7256e6-5434-42ae-ff63-9e77138b586f"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels\n",
        "\n",
        "lrs = np.logspace(-4, -1, 20) # different learning rates to try\n",
        "times = []\n",
        "\n",
        "for lr in lrs:\n",
        "  model = Logistic_regression()\n",
        "  print(\"learning rate: \", lr)\n",
        "  t1 = time.time()\n",
        "  w = model.fit(X, y, learning_rate=lr)\n",
        "  t2 = time.time()\n",
        "  print(\"time: \", t2-t1)\n",
        "  times.append(t2-t1)\n",
        "\n",
        "plt.plot(times)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate:  0.0001\n",
            "Early stop at iteration:  1603\n",
            "time:  0.05707907676696777\n",
            "learning rate:  0.0001438449888287663\n",
            "Early stop at iteration:  1778\n",
            "time:  0.11549639701843262\n",
            "learning rate:  0.00020691380811147902\n",
            "Early stop at iteration:  1850\n",
            "time:  0.11096906661987305\n",
            "learning rate:  0.00029763514416313193\n",
            "Early stop at iteration:  1832\n",
            "time:  0.10595107078552246\n",
            "learning rate:  0.00042813323987193956\n",
            "Early stop at iteration:  1738\n",
            "time:  0.09921121597290039\n",
            "learning rate:  0.0006158482110660267\n",
            "Early stop at iteration:  1588\n",
            "time:  0.0923922061920166\n",
            "learning rate:  0.0008858667904100823\n",
            "Early stop at iteration:  1403\n",
            "time:  0.08155608177185059\n",
            "learning rate:  0.0012742749857031334\n",
            "Early stop at iteration:  1203\n",
            "time:  0.0715627670288086\n",
            "learning rate:  0.0018329807108324356\n",
            "Early stop at iteration:  1006\n",
            "time:  0.06218385696411133\n",
            "learning rate:  0.0026366508987303583\n",
            "Early stop at iteration:  823\n",
            "time:  0.05341815948486328\n",
            "learning rate:  0.00379269019073225\n",
            "Early stop at iteration:  662\n",
            "time:  0.04109811782836914\n",
            "learning rate:  0.005455594781168515\n",
            "Early stop at iteration:  523\n",
            "time:  0.03232169151306152\n",
            "learning rate:  0.007847599703514606\n",
            "Early stop at iteration:  409\n",
            "time:  0.02336287498474121\n",
            "learning rate:  0.011288378916846883\n",
            "Early stop at iteration:  315\n",
            "time:  0.020818471908569336\n",
            "learning rate:  0.01623776739188721\n",
            "Early stop at iteration:  240\n",
            "time:  0.016218900680541992\n",
            "learning rate:  0.023357214690901212\n",
            "time:  0.30832338333129883\n",
            "learning rate:  0.03359818286283781\n",
            "time:  0.31224560737609863\n",
            "learning rate:  0.04832930238571752\n",
            "time:  0.30222153663635254\n",
            "learning rate:  0.06951927961775606\n",
            "time:  0.2805159091949463\n",
            "learning rate:  0.1\n",
            "time:  0.18823814392089844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f63d9d440b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnk43sy4QlCxACCGGHABIUXKiirRtu6NVqa6+1tz56++uvi11+tfV6e21te7tcW2vVXqtWVNRKK621gisECTsBgRAJWYCEBLKaTJbv7485iWMMMJrMnDMzn+fjkUdmzjLzYZi858z3nPM5YoxBKaVU+IqyuwCllFKBpUGvlFJhToNeKaXCnAa9UkqFOQ16pZQKc9F2FzCQ2+0248ePt7sMpZQKKVu2bDlujMkabJ7jgn78+PGUlpbaXYZSSoUUEak81TwdulFKqTCnQa+UUmFOg14ppcKcBr1SSoU5DXqllApzGvRKKRXmNOiVUirMOe44eqWU8pcxhiNNHRyoa6W8rpWRyXFcNG0UcdEuu0tzFA16pZTj9fYaqk+8z4G6Fg7UtXLgWCvldS2U17XS5un50LLupFhWzh/LjQvHkp02wqaKnUWDXinlGN09vVQ2tvcHeV+oVxxvpaOrt3+5kclxTBqVxLVFeUwcmcSkkUkUjEyirLaZxzce4oHXyvnNa+V8qnAUn100nuKCTETEvn+YzTTolVKO8MO/lPFESSVdPR9c9S4nbQQTRyZRXJDJpFFJTByZzMSRSaSOiBn0MZZOzmLp5CyqGtt5ctNhnt58mJfLjlGQlcjNZ49jxbxcUuIHXzecidMuJVhUVGS0141Skee8+9czIjaaL5yTz6RRSRRkJZEYN7Rt0Y6uHl7aeYQ/llSyo+okCbEurpqTw2cXjees0cnDVLkziMgWY0zRYPN0i14p5QgNbR5WTM7i6nm5w/aY8TEurp6Xy9XzctlZfZI/bqxk9ZZqntx0mAX5GXx20TgunjaaGFd4H4Do179ORJaLyD4RKReRuwaZf4eI7BKR7SLylogU+sz7trXePhG5eDiLV0qFB093Ly0d3WQkxgXsOWbmpvHTa2dR8u0L+c6lUzja1MGdf9rG4vvW8d+v7OdYc0fAnttuZwx6EXEBDwCXAIXADb5BbvmTMWaGMWY28BPg59a6hcBKYBqwHPiN9XhKKdXvRLsHgIyk2IA/V3piLLcvKeC1r5/HH26dz7TsFH617gDF963j7hd3093Te+YHCTH+DN0sAMqNMRUAIrIKuALY07eAMabZZ/lEoG/g/wpglTGmE3hPRMqtx9s4DLUrpcJEQ6s36DMTAx/0faKihPOnjOT8KSOpbGjj929W8NjGSmpOvs+vb5jLiNjw2Sb1Z+gmB6jyuV9tTfsQEfmyiBzEu0X/lY+57u0iUioipfX19f7WrpQKE41t1hZ9EIPe17jMRO69cgb3XjmdV9+t46ZHNnHS+pYRDoZtD4Qx5gFjTAHwLeB7H3Pdh4wxRcaYoqysQa+EpZQKYw1tnUBwt+gHc9PZ4/jNjXPZVd3EtQ9upPbk+7bWM1z8CfoaIM/nfq417VRWAVd+wnWVUhHI7i16X5fMGMMfb1vA0aYOrv7tBg4ca7G7pCHzJ+g3A5NEJF9EYvHuXF3ju4CITPK5+2nggHV7DbBSROJEJB+YBLwz9LKVUuGksc2DCKQl2B/0AGdPyOTpLy6iu9dwzYMb2VLZaHdJQ3LGoDfGdAN3Ai8De4FnjDFlInKPiFxuLXaniJSJyHbga8At1rplwDN4d9z+HfiyMabnI0+ilIpoDW0e0hNicUU5p01BYXYKz3+pmIzEWP7l4U38c88xu0v6xPTMWKWU7e54fAvl9a3882tL7S7lIxpaO/nc/26mrLaZ/1oxg+uK8s68kg1Od2ZseJ8OppQKCY1tHkeMzw8mMymOp/71bIoLMvnm6p08sL4cp20gn4kGvVLKdg1tnbYfcXM6iXHRPHLLfK6cnc39L+/jh3/ZQ29v6IS99rpRStnOyVv0fWKjo/j5dbNxJ8Xx8Fvvcby1k59dNyskLnKiQa+UslVPr+Hk+12O3qLvExUlfO8zhYxMieNHa9/lRLuHB2+aR7LDWx/r0I1SylYn2j0Y44xj6P11+5ICfnbtLEoqGln5UAn1LZ12l3RaGvRKKVv1nyyVFLjOlYFw9bxcHr6liIr6Nq55cAOVDW12l3RKGvRKKVvZ0dBsuJx/1kj+9K8LaX6/i6t/u4HdNU12lzQoDXqllK2c1P7gk5gzNp3VXyomxhXFt5/fZXc5g9KgV0rZqtEhDc2GoiAriRsWjGV3bRMn2pzX9VKDXillqwYrGNNDOOgBFk/MxBgoqWiwu5SP0KBXStmqsc1DSnx0yF+3dWZuGomxLt4+eNzuUj4itF9ZpVTIa2jzkBliR9wMJsYVxYL8DDYc1C16pZT6kMZW558V66/FE91U1LdxtMlZFxrXoFdK2SoU2h/4a1FBJgAbHDZ8o0GvlLJVQ5sHd1J4BP3U0SmkJ8Twdrmzhm806JVStuntNZxoD58t+qgoYVFBJhsPHndUK2MNeqWUbZo7uujpNWQkhv7O2D7FBW5qmzo41NBudyn9NOiVUrbpO4Y+lE+WGqjYgeP0GvRKKduEevuDweS7ExmTGs8GB43Ta9ArpWzT19AsnIJeRCgucLPh4HHHXIVKg14pZZu+LfrMMDnqpk9xQSYn2rt492iL3aUAGvRKKRv1NTQLpy16gOKJzhqn16BXStmmoc1DUlx0SFx39eMYkzqCCe5Ex7RD0KBXStkmnM6KHah4YiabKhro6um1uxQNeqWUfcI66AvctHl62Flt/1Wn/Ap6EVkuIvtEpFxE7hpk/tdEZI+I7BSRV0VknM+8HhHZbv2sGc7ilVKhraHVE1bH0PtaNMEapy+3f5z+jEEvIi7gAeASoBC4QUQKByy2DSgyxswEVgM/8Zn3vjFmtvVz+TDVrZQKAw1tnWG7RZ+eGEvhmBRHjNP7s0W/ACg3xlQYYzzAKuAK3wWMMeuNMX3n+5YAucNbplIq3BhjvEM3YXZopa/FEzPZcvgEHV09ttbhT9DnAFU+96utaadyG/A3n/vxIlIqIiUicuVgK4jI7dYypfX19X6UpJQKdS2d3XT1mLAdugEonujG093LlsoTttYxrDtjReQmoAi432fyOGNMEXAj8AsRKRi4njHmIWNMkTGmKCsrazhLUko5VGP/WbHh09BsoAXjM4iOEt62eZzen6CvAfJ87uda0z5ERJYB3wUuN8Z09k03xtRYvyuA14A5Q6hXKRUmwrGh2UCJcdHMzkvjbZvH6f0J+s3AJBHJF5FYYCXwoaNnRGQO8Du8IV/nMz1dROKs225gMbBnuIpXSoWucGxoNpjigkx2VZ+kuaPLthrOGPTGmG7gTuBlYC/wjDGmTETuEZG+o2juB5KAZwccRjkVKBWRHcB64D5jjAa9Uips2x8MVDzRTa+BTRWNttUQ7c9Cxpi1wNoB077vc3vZKdbbAMwYSoFKqfDUEKYNzQaaMzaN+JgoNhw8zqcKR9lSg54Zq5SyRWOrh/iYKBJi/dreDFlx0S7mj8+wtT+9Br1SyhaNbR4yw/iIG1+LCjLZd6yF+pbOMy8cABr0SilbNIRxn5uBFhe4AdhYYc9WvQa9UsoW4dzQbKDpOakkx0ez0ab+9Br0SilbeIduIiPoXVHC2RMyedumcXoNeqWULcK5odlgFhdkcrixnarG9jMvPMw06JVSQdfu6aajqzesG5oNVDzRGqe34SxZDXqlVNA1tIZ/+4OBJo1Mwp0Ux9s2jNNr0Culgu6D9geRcXglgIhQXJDJhoMNGGOC+twa9EqpoIuUPjcDLZ6YSX1LJ+V1rUF9Xg16pVTQRULnysEUW8fTB/uqUxr0Sqmg629oFkE7YwHyMhLIyxgR9P70GvRKqaBraPMQ4xKS48K7z81gFhe4KalooKc3eOP0GvRKqaBrbPWeFSsidpcSdIsKMmnu6Kastiloz6lBr5QKOm/7g8g54saXHeP0GvRKqaBriKD2BwNlJccxeVRSUMfpNeiVUkEXSQ3NBlNc4GbzoUY6u3uC8nwa9EqpoNOgz6Sjq5fth08G5fk06JVSQdXZ3UNrZzfuCDu00tfCCZlECbwdpHF6DXqlVFBFYvuDgVJHxDAjJzVo/ek16JVSQdXX0CySh27A281y2+GTtHV2B/y5NOiVUkHVt0WfGcFDN+A9caq717D5UGPAn0uDXikVVJHa0GygeePSiXVFBeV4eg16pVRQRWpDs4FGxLqYOy6NDUEYp/cr6EVkuYjsE5FyEblrkPlfE5E9IrJTRF4VkXE+824RkQPWzy3DWbxSKvQ0tnXiihJS4mPsLsV2xQVuymqbOdnuCejznDHoRcQFPABcAhQCN4hI4YDFtgFFxpiZwGrgJ9a6GcDdwEJgAXC3iKQPX/lKqVDT2OYhPSGWqKjI63Mz0OKJmRgT+MsL+rNFvwAoN8ZUGGM8wCrgCt8FjDHrjTF9V7wtAXKt2xcDrxhjGo0xJ4BXgOXDU7pSKhQ1tEZu+4OBZuamkRjrCvg4vT9BnwNU+dyvtqadym3A3z7OuiJyu4iUikhpfX29HyUppUJVpJ8V6yvGFcWC/IyAX0d2WHfGishNQBFw/8dZzxjzkDGmyBhTlJWVNZwlKaUcprHNE3EXHDmd4gI3FfVtHG3qCNhz+BP0NUCez/1ca9qHiMgy4LvA5caYzo+zrlIqckRy58rBFE/MBAjo0Tf+BP1mYJKI5ItILLASWOO7gIjMAX6HN+TrfGa9DFwkIunWTtiLrGlKqQjU1dNL0/tdOnTjY+roFNITYgI6Tn/G63gZY7pF5E68Ae0CHjXGlInIPUCpMWYN3qGaJOBZ64oxh40xlxtjGkXkP/B+WADcY4wJ/GlgSilHOtGux9APFBUlLCrIZEP5cYwxAbnqll8XbDTGrAXWDpj2fZ/by06z7qPAo5+0QKVU+NCGZoMrLnCzdtdRKhvaGe9OHPbH1zNjlVJB06gNzQZVXOAdpw/U0Tca9EqpoGnQhmaDyncnMiY1ng3lgRmn16BXSgWNNjQbnIjwqcJRxMUEJpL9GqNXSqnh0NDmQQTSEzToB7rniukBe2zdoldKBU1DaydpI2JwaZ+boNKgV0oFjbY/sIcGvVIqaLxnxeqhlcGmQa+UChrdoreHBr1SKmi0oZk9NOiVUkHR02s40a4NzeygQa+UCoqT7R6M0WPo7aBBr5QKCj1Zyj4a9EqpoOhvf6BH3QSdBr1SKih0i94+GvRKqaDQhmb20aBXSgVFX4ti7XMTfBr0SqmgaGzrJDk+mthojZ1g01dcKRUUelFw+2jQK6WCQtsf2EeDXikVFN6g10Mr7aBBr5QKCh26sY8GvVIq4IwxnNCGZrbRoFdKBVzz+9109xrdoreJBr1SKuAa2joBPVnKLn4FvYgsF5F9IlIuIncNMn+JiGwVkW4RuWbAvB4R2W79rBmuwpVSoeOD9ge6M9YO0WdaQERcwAPAp4BqYLOIrDHG7PFZ7DBwK/D1QR7ifWPM7GGoVSkVoj5oaKZb9HY4Y9ADC4ByY0wFgIisAq4A+oPeGHPImtcbgBqVUiFOG5rZy5+hmxygyud+tTXNX/EiUioiJSJy5ceqTikVFjTo7eXPFv1QjTPG1IjIBGCdiOwyxhz0XUBEbgduBxg7dmwQSlJKBVNDq4fEWBfxMS67S4lI/mzR1wB5PvdzrWl+McbUWL8rgNeAOYMs85AxpsgYU5SVleXvQyulQkRjW6ceQ28jf4J+MzBJRPJFJBZYCfh19IyIpItInHXbDSzGZ2xfKRUZGrT9ga3OGPTGmG7gTuBlYC/wjDGmTETuEZHLAURkvohUA9cCvxORMmv1qUCpiOwA1gP3DThaRykVARq1/YGt/BqjN8asBdYOmPZ9n9ub8Q7pDFxvAzBjiDUqpUJcY5uHqWNS7C4jYumZsUqpgDLGaEMzm2nQK6UCqs3Tg6e7Vw+ttJEGvVIqoPquFatBbx8NeqVUQGlDM/tp0CulAkobmtlPg14pFVDa0Mx+GvRKqYDSPjf206BXSgVUY5uHuOgoEmK1z41dNOiVUgHV0Oo9hl5E7C4lYmnQK6UCShua2U+DXikVUI3a0Mx2GvRKqYDS9gf206BXSgWUd4teg95OGvRKqYDp6Oqh3dOjQW8zDXqlVMDoyVLOoEGvlAoYbWjmDBr0Plo6uujq6bW7DKXCxnFtaOYIfl1hKhLUNXdw3k9fo7vHMHl0EtPGpFKYnUJhdgpTRieTHB9jd4lKhZwPtuj18Eo7adBbVm2uot3Tw63F4zlY38ore4/xdGlV//zxmQne4B+TwrRs74fAyOQ4PdtPqdPQPjfOoEEPdPf08tQ7hzl3kpsfXD4N8F7+7FhzJ3uONFFW08yeI82U1TazdtfR/vUyE2P7t/q9HwAp5LuTcEVp+CsF3p2xMS4hJV6jxk766gPr3q3jSFMHd182rX+aiDA6NZ7RqfFcMGVU//Tmji7ePdLCntqm/vB/9K336OoxACTGupiRm8qs3DRm5aUxMzeVnLQRuuWvIlJjWyfpCdrnxm4a9MATmw4zOiWeZVNHnnHZlPgYFuRnsCA/o3+ap7uXg/Wt7K5pYldNEzuqTvKHtw/hsXbsupNimZWbxszcNGbleT8E0vWrrIoAerKUM0R80Fc2tPHG/nq+umwS0a5PdhBSbHQUU8ekMHVMCtcW5QHQ2d3Du0da2Fl9ku1VTeysPsm6fXUY74Y/YzMSmJmbyuw875b/tOwUEmIj/r9DhZmGNo8eceMAEZ8sf9p0GFeUcMOCscP6uHHRLmZZIX7zIu+0lo4udtU0sbPau9W/7fBJ/rrzCABRApNHJbOoIJOlk7M4e0Im8THav1uFtsY2D7npaXaXEfEiOug7unp4prSKiwpHMSolPuDPlxwfQ3GBm+ICd/+0+pZOdlaf9AZ/1Un+tOkwf3j7ELHRUSzMz2Dp5CzOOyuLgqwkHedUIaexVRuaOYFfQS8iy4FfAi7gYWPMfQPmLwF+AcwEVhpjVvvMuwX4nnX3XmPMY8NR+HBYu+sIJ9q7uOnscbbVkJUcx4VTR3HhVO8O346uHt55r5HX99fz+v567n1pL/e+tJectBEsmZzF0slZLJ6Yqcf1K8fr7O6hpbNbx+gd4IxBLyIu4AHgU0A1sFlE1hhj9vgsdhi4Ffj6gHUzgLuBIsAAW6x1TwxP+UPzREklE9yJFBdk2l1Kv/gYF0smZ7Fkchb/D6g+0c4b+4/z+v46/rKjlqfeOUx0lDB3XDpLreAvHJNClB7SqRzmRFsXoMfQO4E/W/QLgHJjTAWAiKwCrgD6g94Yc8iaN7B/wMXAK8aYRmv+K8By4KkhVz5Ee2qb2Xr4JN/79FRHD4nkpidw48Kx3LhwLF09vWytPMEbB7xb+/e/vI/7X96HOymWJZOyWHpWFudOytI/LOUIDVb7A7fujLWdP0GfA1T53K8GFvr5+IOtmzNwIRG5HbgdYOzY4d0peipPbKokLjqKa+blBuX5hkOMK4qFEzJZOCGTb1w8hfqWTt60Qn/9vjqe31aDCMzMTeM8a2x/Zm6ansClbPHBWbHa/sBujtgZa4x5CHgIoKioyAT6+Vo6uvjzthoum5VNWkLobm1kJcexYm4uK+bm0tNr2FXTxOv76nltfx2/WneAX756gPSEGM6d5A39JZOzcCfpH50KDm1/4Bz+BH0NkOdzP9ea5o8a4LwB677m57oB8+dtNbR7emzdCTvcXFHC7Lw0Zuel8e/LJnGizcOb5cd5bV8db+yvZ82OWgBm5KRy3lne4J+Vm/aJzx1Q6kwaWrUXvVP4E/SbgUkiko83uFcCN/r5+C8DPxKRdOv+RcC3P3aVw8gYwxMlh5mek8Ks3FQ7Swmo9MRYLp+VzeWzsuntNZTVNvP6/jpe21fPA+vL+fW6clJHxHDOJDfnWTt1RwbhEFMVORrbPLiihNQReoSY3c4Y9MaYbhG5E29ou4BHjTFlInIPUGqMWSMi84EXgHTgMhH5oTFmmjGmUUT+A++HBcA9fTtm7bL50An2HWvhx1fPcPRO2OEUFSXMyE1lRm4qd14wiab2Lt4sr+e1fd7x/Zesk7YKx6SwYm4OKxeMJSnOEaN6KoQ1tHlIT4jRI8IcQIwJ+JD4x1JUVGRKS0sD9vhfeWob6/fVsek7F2rLAbzfcPYcaea1ffX8c+8xth0+SXJcNDcuHMuti8czJnWE3SWqEPXFx0t573gb//g/S+0uJSKIyBZjTNFg8yIq6Y63dvK33Uf4l4XjNOQtIsK07FSmZafy5fMnsr3qJL9/s4Lfv1nBI2+9x2WzsvnCuflMyw7fYS4VGNrQzDkiKu2eKa2iq8dw09nBOYQzFM3OS+OBG+dS1djOo2+/x9Obq3hhWw3nTHTzhXPzWTo5K2KGvNTQNLR5mDo6xe4yFBF0zdieXsOfNh3m7AkZTByZbHc5jpeXkcDdl01j410X8q3lU9h/rIVb/7CZ5b94k2dLq+js7rG7ROVwukXvHBET9G/sr6f6xPthdUhlMKQmxPCl8wp461sX8NNrZyEC31i9k3N+vJ4H1pdzst1jd4nKgbp7ejnZ3qVB7xARM3TzREkl7qQ4LiocbXcpISnWOov46rk5vHngOL9/s4L7X97H/6wr5/r5eXx+cT5jMxPsLlM5xIl2b58b7UXvDBER9NUn2lm3r44vnzeR2OiI+RITECLS33RtT20zD79VwZObKvnjxkMsnz6azy/OZ964dB3Hj3B6VqyzRETQP/XOYQS4YaHuhB1Ohdkp/Py62Xzz4in874ZDPLmpkrW7jjJ1TAo3nz2OK+dk69FNEaqvoZkGvTOE/eatp7uXpzdXccGUUeSk6THhgTA6NZ67LplCybcv5EdXzcAYw3de2MXCH73KD/9SxsH6VrtLVEHWt0WfqQ3NHCHsN7f+XnaU460ePaQyCBKtE61uWJBHaeUJHt9YyRMllfzh7UOcM9HNzYvGceGUkdpfJwLo0I2zhH3QP1FSydiMBJZMyrK7lIghIswfn8H88RnUtUzlmc1VPLnpMF98fAvZqfHcuHAs188fS1aybu2Fq76GZukJ2ufGCcJ602r/sRbeea+RGxeO1X4bNhmZHM+dF0zizW+ez4M3zWNCVhI//cd+iu97la88tY3SQ404rQ2HGrrGNg9pCTH67c0hwnqL/smSSmJdUVwbQhcXCVfRriiWTx/N8umjKa9r5YmSSp7bUs2aHbVMHZPCZxeN44rZuvM2XOjJUs4Sth+3bZ3dPL+1hktnjCZTL7bhKBNHJvGDy6ex6bsf7Lz99vPenbd3v7ibvUea7S5RDVFDW6f2oXeQsN18WrOjlpbObj0T1sESYj/Yebul8gSPl1Ty1DtVPLaxklm5qVw/fyyXzRpDcryO84aaxjYP+e5Eu8tQlrDcovdeXKSSKaOTmTcu/cwrKFuJCEXjM/jlyjls+s6F3H1ZIR1dvXznhV0s+M9X+cazO9hSqWP5ocQ7dKPfpJ0iLLfot1edpKy2mXuvnK5naIaY9MRYPrc4n1uLx7OjuomnNx9mzfZant1SzcSRSaycn8dVc3J0OM7BensNJ9q7dOjGQcIy6B8vqSQx1sWVc3LsLkV9QiIfXAP3e58u5KWdR1i1+TD3vrSXH//9XS6aNpqV8/NYXODWI6ocpun9Lnp6je6MdZCwC/oTbR7+uvMI1xXl6uXwwkRiXDTXzc/juvl57DvawtObq3h+WzUv7TxCTtoIrp+fx7VFuXo1LIdo6DsrVhuaOUbYJeHqLdV4unt1J2yYOmt0Mt+/rJBvXXIW/yg7xtObq/j5K/v5xT/3s3RyFtcW5XHBlJHEx7jsLjVi6VmxzhNWQd/ba3hyUyVF49KZole2CWtx0S4um5XNZbOyOdzQzrNbqni2tJp/e3IrKfHRfHpmNivm5lCknTSDrlEbmjlOWAX92wePc6ihna8um2x3KSqIxmYm8H8vOouvLpvMhoPHeX5rDX/eVsNT7xxmbEYCV83JYcXcHMZl6uF+wdCgDc0cJ6yC/omSSjISY7lkhl5cJBK5ooRzJ2Vx7qQs7r2ym7/vPsoL22r41boD/PLVA8wbl85Vc3L4zMwxpCXo1magNPb1uUnU8x+cImyC/mhTB//cW8cXzs0nLlrHZyNdYlw0V8/L5ep5uRxpep8Xt9fy/NZqvvfn3dzzlz1cMGUkK+bmcN5ZI/ViNMOsoc1Dcly0/h06SNgEfVpCDD++eiYL8zPsLkU5zJjUEdyxtIAvLplAWW0zz2+tYc2OGv5edpT0hBgum5XNVXNymJ2XpuP5w6CxzUOGHnHjKH4FvYgsB34JuICHjTH3DZgfB/wRmAc0ANcbYw6JyHhgL7DPWrTEGHPH8JT+YfExLq7R5mXqNESE6TmpTM9J5duXTuGtA8d5bms1T2+u4o8bK5ngTuTmReO4YcFYPWpnCLShmfOcMehFxAU8AHwKqAY2i8gaY8wen8VuA04YYyaKyErgx8D11ryDxpjZw1y3UkMS44ri/CkjOX/KSJo7uvjbriM8U1rND/+yh4feqODOCyZy7bw8Hdb5BBraPOSkxdtdhvLhz7t4AVBujKkwxniAVcAVA5a5AnjMur0auFD0O7AKESnxMVw/fyyr71jEk19YyJjUeL77wm4u+NlrPFtaRXdPr90lhpTGtk7doncYf4I+B6jyuV9tTRt0GWNMN9AEZFrz8kVkm4i8LiLnDvYEInK7iJSKSGl9ff3H+gcoNVxEhMUT3Tz3pWL+8Ln5pCfE8o3VO7nov9/gxe019PZqU7UzMcZoQzMHCvT30iPAWGPMHOBrwJ9E5CNnMhljHjLGFBljirKy9JJ/yl4iwvlnjWTNnYv53c3ziI2O4t9XbWf5L9/g77uPaBfN02ju6Karx2hDM4fxJ+hrgDyf+7nWtEGXEZFoIBVoMMZ0GmMaAIwxW4CDgJ7NpEKCiHDxtNGs/cq5/PqGOXT3Gu54Yiuf+fVbvLr3mAb+ILT9gTP5E/SbgUkiki8iscBKYM2AZdYAt1i3rwHWGWOMiGRZO3MRkaOh7q0AAAoySURBVAnAJKBieEpXKjiiooTLZmXzj68u4WfXzqKlo5vbHivlqt9s4M0D9Rr4PvrbH+jhlY5yxqC3xtzvBF7Ge6jkM8aYMhG5R0QutxZ7BMgUkXK8QzR3WdOXADtFZDvenbR3GGMah/sfoVQwRLuiuHpeLq/+36X814oZ1DV3cPMj73D9QyVsqmiwuzxHaLDOinXrGL2jiNO2RoqKikxpaandZSh1Rp3dPax6p4r/WV9OfUsn50x088WlEygucOOK0B75q945zF3P7+Ltuy4gJ03bRgeTiGwxxhQNNi9szoxVKtjiol3cUjye64ryeKKkkt++fpCbH3mH0SnxXGk1Ups8KtnuMoPqg4ZmOnTjJBr0Sg3RiFgX/7pkAjcvGsc/9x7j+a01/P7NCh58/SDTc1JYMSeXy2dn446Ayx82tnlIiHXpmcUOo0Gv1DCJj3HxmZnZfGZmNsdbO1mzvZYXttVwz1/38J9r97J0chYr5uawbOqosA1CbX/gTBr0SgWAOymOz5+Tz+fPyWf/sZb+Hvnr3q0jOS6aT88cw4q5uRSNSw+ra942tHl02MaBNOiVCrDJo5K565IpfOPisyipaOC5rdWs2VHLqs1V5GWM4KrZOVw1N5d8d+hfGKWxrZOsCBiiCjUa9EoFiSvK22Jh8UQ3917ZzctlR3l+aw2/Xl/Or9aVM2dsGlfPzeWymdmkJoTmRTsaWz2cNUov4+k0GvRK2SAhNpqr5uRy1ZxcjjZ18OL2Gp7ruzDKX/fwqcJRXDMvl3Mnuol2hUYHTWOMd+hGT5ZyHA16pWw2OjWeLy4t4Hbrwiirt1Tz4vYaXtp5hKzkOFbMyeHqebmOP1Sz3dNDZ3ev7ox1IA16pRzC98Io37l0KuverWP1lmoeees9fvdGBTNzU7lmnndoJ92BYap9bpxLg14pB4qNjmL59NEsnz6a462dvLi9lue2VPP9F8v4j7/uYdlU79DOkslZxDhkaEdPlnIuDXqlHM6dFMdt5+Rz2zn57Klt5rmt1fx5Ww1/230Ud1IsV872Du1MHWPvTtD+hmYa9I6jQa9UCCnMTqEwu5C7LpnC6/vqWb2lmsc2HuLht95jWnYKxQWZjEqJZ3RqPKNT4hll/QTjkoh9Dc0ytaGZ42jQKxWCYlxRLCscxbLCUTS2efjLjlqe31bD4yWVdHR99NKH7qRY7wdASjyjrA+BvttjUr0fBinx0QzlCqD9Y/R61I3jaNArFeIyEmO5pXg8txSPxxhD0/tdHG3u4GhTB8eaOzja1MnRZu/t2qYOtlWd7A9lXyNiXIx3JzItO4Xp2SlMy0ll6pgUkuL8i4nGNg+x0VEkxoZne4dQpkGvVBgREdISYklLiGXK6FOP2Xd291DX3Nn/gXC0qYMjTR2U17fy2j7v0T7ex4PxmYkUZqcwLTuFadmpTMtOGbRBW1/7g6F8K1CBoUGvVASKi3aRl5FAXkbCR+YZY6hr6WR3TRNltc2U1Taxo+okL+080r/MqJQ4pluhX2j91oZmzqVBr5T6EBHp34l74dRR/dOb2rsoO9LEntrm/g+A9fvq6PW5dtG5k9w2VKzORINeKeWX1IQYigvcFBd8EOYdXT28e7SFslrvB8Aynw8G5Rwa9EqpTyw+xsXsvDRm56XZXYo6DWecUqeUUipgNOiVUirMadArpVSY06BXSqkwp0GvlFJhToNeKaXCnAa9UkqFOQ16pZQKc2KMOfNSQSQi9UDlEB7CDRwfpnICQesbGq1vaLS+oXFyfeOMMVmDzXBc0A+ViJQaY4rsruNUtL6h0fqGRusbGqfXdyo6dKOUUmFOg14ppcJcOAb9Q3YXcAZa39BofUOj9Q2N0+sbVNiN0SullPqwcNyiV0op5UODXimlwlxIBr2ILBeRfSJSLiJ3DTI/TkSetuZvEpHxQawtT0TWi8geESkTkX8fZJnzRKRJRLZbP98PVn0+NRwSkV3W85cOMl9E5FfWa7hTROYGsbazfF6b7SLSLCJfHbBMUF9DEXlUROpEZLfPtAwReUVEDli/00+x7i3WMgdE5JYg1ne/iLxr/f+9ICKDXh3kTO+FANb3AxGp8fk/vPQU65727z2A9T3tU9shEdl+inUD/voNmTEmpH4AF3AQmADEAjuAwgHL/BvwoHV7JfB0EOsbA8y1bicD+wep7zzgrza/jocA92nmXwr8DRDgbGCTjf/fR/GeDGLbawgsAeYCu32m/QS4y7p9F/DjQdbLACqs3+nW7fQg1XcREG3d/vFg9fnzXghgfT8Avu7H//9p/94DVd+A+T8Dvm/X6zfUn1Dcol8AlBtjKowxHmAVcMWAZa4AHrNurwYuFBEJRnHGmCPGmK3W7RZgL5ATjOceZlcAfzReJUCaiIyxoY4LgYPGmKGcLT1kxpg3gMYBk33fZ48BVw6y6sXAK8aYRmPMCeAVYHkw6jPG/MMY023dLQFyh/t5/XWK188f/vy9D9np6rOy4zrgqeF+3mAJxaDPAap87lfz0SDtX8Z6ozcBmUGpzoc1ZDQH2DTI7EUiskNE/iYi04JamJcB/iEiW0Tk9kHm+/M6B8NKTv0HZvdrOMoYc8S6fRQY7MrYTnkdP4/3G9pgzvReCKQ7raGlR08x9OWE1+9c4Jgx5sAp5tv5+vklFIM+JIhIEvAc8FVjTPOA2VvxDkXMAn4N/DnY9QHnGGPmApcAXxaRJTbUcFoiEgtcDjw7yGwnvIb9jPc7vCOPVRaR7wLdwJOnWMSu98JvgQJgNnAE7/CIE93A6bfmHf+3FIpBXwPk+dzPtaYNuoyIRAOpQENQqvM+ZwzekH/SGPP8wPnGmGZjTKt1ey0QIyLuYNVnPW+N9bsOeAHvV2Rf/rzOgXYJsNUYc2zgDCe8hsCxvuEs63fdIMvY+jqKyK3AZ4B/sT6MPsKP90JAGGOOGWN6jDG9wO9P8bx2v37RwArg6VMtY9fr93GEYtBvBiaJSL61xbcSWDNgmTVA39EN1wDrTvUmH27WeN4jwF5jzM9Psczovn0GIrIA7/9DMD+IEkUkue823p12uwcstgb4rHX0zdlAk88wRbCcckvK7tfQ4vs+uwV4cZBlXgYuEpF0a2jiImtawInIcuCbwOXGmPZTLOPPeyFQ9fnu87nqFM/rz997IC0D3jXGVA82087X72Oxe2/wJ/nBe0TIfrx7479rTbsH7xsaIB7v1/1y4B1gQhBrOwfvV/idwHbr51LgDuAOa5k7gTK8RxCUAMVBfv0mWM+9w6qj7zX0rVGAB6zXeBdQFOQaE/EGd6rPNNteQ7wfOEeALrzjxLfh3e/zKnAA+CeQYS1bBDzss+7nrfdiOfC5INZXjnd8u+992HckWjaw9nTvhSDV97j13tqJN7zHDKzPuv+Rv/dg1GdN/9++95zPskF//Yb6oy0QlFIqzIXi0I1SSqmPQYNeKaXCnAa9UkqFOQ16pZQKcxr0SikV5jTolVIqzGnQK6VUmPv/u8o61sV2If4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}