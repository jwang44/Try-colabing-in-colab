{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECSE01_2_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/ECSE01_2_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oskj54Fv8eGB",
        "outputId": "e4626a60-c650-42f7-dded-359be7774017"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFoqVsWOP14"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7_Y_eMDpQX4"
      },
      "source": [
        "def sigmoid(a):\r\n",
        "  return 1/(1+np.exp(-a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrl86Dhy9jy"
      },
      "source": [
        "class Logistic_regression():\n",
        "  def __init__(self,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.learning_rate = learning_rate\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "\n",
        "  def fit(self):\n",
        "    n,m = np.shape(self.X_train)\n",
        "    itrnum = 500\n",
        "    W = np.ones([m+1,itrnum+1])\n",
        "    e = 0.01        \n",
        "    der = 0\n",
        "    for k in range(0,itrnum):\n",
        "      for i in range(0,n):\n",
        "        xi = self.X_train[i].T\n",
        "        x0 = np.array([1])\n",
        "        xi = np.concatenate((xi, x0),axis = 0)\n",
        "        yi = self.y_train[i]\n",
        "        der = der-xi*(yi-sigmoid(np.matmul(W[:,k].T,xi)))\n",
        "      W[:,k+1] = W[:,k]-self.learning_rate*der\n",
        "      if (np.linalg.norm(W[:,k+1]-W[:,k]))**2<e:\n",
        "        break \n",
        "    return W[:,k+1]\n",
        "  \n",
        "  def predict(self):\n",
        "    w = self.fit()\n",
        "    n,m = np.shape(self.X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      xi = self.X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi))\n",
        "      #p0=1-sigmoid(np.matmul(w.T,xi))\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  '''def Accu_eval(self):\n",
        "    y_predict = self.predict()\n",
        "    n,i = np.shape(y_predict)\n",
        "    err = np.sum(np.abs(y_predict-self.y_test))\n",
        "    accuracy = 1-err/n\n",
        "    return accuracy'''\n",
        "  \n",
        "  def Accu_eval(self):\n",
        "    y_predict = self.predict()\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    print(\"precision:\",precision)\n",
        "    print(\"recall:\",recall)\n",
        "    print(\"F:\",F)\n",
        "    print(\"specificity:\",specificity)\n",
        "    print(\"False Positive Rate:\",FPR)\n",
        "    print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accuracies = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      logistic_regression = Logistic_regression(X_train, y_train, lr, X_test, y_test)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "      accuracy = logistic_regression.Accu_eval()\n",
        "      accuracies.append(accuracy)\n",
        "    return np.mean(accuracies)\n",
        "      # this will print the evaluation results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDn3bsVpsHEz"
      },
      "source": [
        "## Change directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcIZP21G9mu_",
        "outputId": "1a06f60b-4e4c-4fac-c99d-5cfad20d0b63"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_w-5Z0sMsJ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1gREIMPzw7M"
      },
      "source": [
        "### Orthopedic Patients Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc7bhCtyW17b"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('orthopedic_patients.csv')\n",
        "# data = df.to_numpy()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybt1JT3h0JpU"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate')\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData, df['Class']))\r\n",
        "# np.savetxt('normalized_orthopedic_patients.csv', NorPatientData, delimiter=',')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oDHjN7u0rbT"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHfVd9v2elN"
      },
      "source": [
        "# new feature\r\n",
        "NewF = newfeature(df.pelvic_incidence, df.sacral_slope)\r\n",
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df['Class']))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxtJdtJ-4qeZ"
      },
      "source": [
        "### Credit Card Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXiM3pnF5j-2"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "# data = df.to_numpy()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHo1NiB4xWr"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate')\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData,df.iloc[:,-1]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kzCB3F5uWL"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyg90-iG5vCB"
      },
      "source": [
        "NewF1 = newfeature(df.V3, df.V7)\r\n",
        "NewF2 = newfeature(df.V11, df.V12)\r\n",
        "NewF3 = newfeature(df.V12, df.V16)\r\n",
        "NewF4 = newfeature(df.V16, df.V17)\r\n",
        "NewF5 = newfeature(df.V16, df.V18)\r\n",
        "NewF6 = newfeature(df.V17, df.V18)\r\n",
        "# new feature\r\n",
        "NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMYL_506R_G"
      },
      "source": [
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df.iloc[:,-1]))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652dc70e-3a76-4862-efa1-ccbc7adc3c4f"
      },
      "source": [
        "lrs = np.logspace(-6, -1, 6) # different learning rates to try\n",
        "# or we can also try other hyperparameters here\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(data)\n",
        "for lr in lrs:\n",
        "  print(\"----------LEARNING RATE: \", lr, \"----------\")\n",
        "  accu_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"----------AVERAGE ACCURACY\", accu_avg, \"----------\")\n",
        "  print(\"\\n---------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------LEARNING RATE:  1e-06  ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.25125628140703515\n",
            "precision: 0.33783783783783783\n",
            "recall: 0.49504950495049505\n",
            "F: 0.40160642570281124\n",
            "specificity: 0.0\n",
            "False Positive Rate: 1.0\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.30303030303030304\n",
            "precision: 0.3918918918918919\n",
            "recall: 0.5471698113207547\n",
            "F: 0.4566929133858268\n",
            "specificity: 0.021739130434782608\n",
            "False Positive Rate: 0.9782608695652174\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.2777777777777778\n",
            "precision: 0.34591194968553457\n",
            "recall: 0.5851063829787234\n",
            "F: 0.4347826086956521\n",
            "specificity: 0.0\n",
            "False Positive Rate: 1.0\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.21717171717171718\n",
            "precision: 0.30656934306569344\n",
            "recall: 0.4117647058823529\n",
            "F: 0.35146443514644354\n",
            "specificity: 0.010416666666666666\n",
            "False Positive Rate: 0.9895833333333334\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.24242424242424243\n",
            "precision: 0.3032258064516129\n",
            "recall: 0.5280898876404494\n",
            "F: 0.38524590163934425\n",
            "specificity: 0.009174311926605505\n",
            "False Positive Rate: 0.9908256880733946\n",
            "\n",
            "----------AVERAGE ACCURACY 0.2583320643622151  ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  1e-05  ----------\n",
            "----------FOLD  1 ----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9396984924623115\n",
            "precision: 1.0\n",
            "recall: 0.8811881188118812\n",
            "F: 0.9368421052631579\n",
            "specificity: 1.0\n",
            "False Positive Rate: 0.0\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9292929292929293\n",
            "precision: 0.9693877551020408\n",
            "recall: 0.8962264150943396\n",
            "F: 0.9313725490196079\n",
            "specificity: 0.967391304347826\n",
            "False Positive Rate: 0.03260869565217391\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9343434343434344\n",
            "precision: 0.9764705882352941\n",
            "recall: 0.8829787234042553\n",
            "F: 0.9273743016759776\n",
            "specificity: 0.9807692307692307\n",
            "False Positive Rate: 0.019230769230769232\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9040404040404041\n",
            "precision: 0.8487394957983193\n",
            "recall: 0.9901960784313726\n",
            "F: 0.9140271493212669\n",
            "specificity: 0.8125\n",
            "False Positive Rate: 0.1875\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9646464646464646\n",
            "precision: 0.9880952380952381\n",
            "recall: 0.9325842696629213\n",
            "F: 0.9595375722543353\n",
            "specificity: 0.9908256880733946\n",
            "False Positive Rate: 0.009174311926605505\n",
            "\n",
            "----------AVERAGE ACCURACY 0.9344043449571087  ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.0001  ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9246231155778895\n",
            "precision: 1.0\n",
            "recall: 0.8514851485148515\n",
            "F: 0.9197860962566845\n",
            "specificity: 1.0\n",
            "False Positive Rate: 0.0\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.8838383838383839\n",
            "precision: 0.8487394957983193\n",
            "recall: 0.9528301886792453\n",
            "F: 0.8977777777777778\n",
            "specificity: 0.8043478260869565\n",
            "False Positive Rate: 0.1956521739130435\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9191919191919192\n",
            "precision: 0.875\n",
            "recall: 0.9680851063829787\n",
            "F: 0.9191919191919191\n",
            "specificity: 0.875\n",
            "False Positive Rate: 0.125\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.898989898989899\n",
            "precision: 0.8416666666666667\n",
            "recall: 0.9901960784313726\n",
            "F: 0.9099099099099098\n",
            "specificity: 0.8020833333333334\n",
            "False Positive Rate: 0.19791666666666666\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9646464646464646\n",
            "precision: 0.9880952380952381\n",
            "recall: 0.9325842696629213\n",
            "F: 0.9595375722543353\n",
            "specificity: 0.9908256880733946\n",
            "False Positive Rate: 0.009174311926605505\n",
            "\n",
            "----------AVERAGE ACCURACY 0.9182579564489112  ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.001  ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9246231155778895\n",
            "precision: 1.0\n",
            "recall: 0.8514851485148515\n",
            "F: 0.9197860962566845\n",
            "specificity: 1.0\n",
            "False Positive Rate: 0.0\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9292929292929293\n",
            "precision: 0.96\n",
            "recall: 0.9056603773584906\n",
            "F: 0.9320388349514563\n",
            "specificity: 0.9565217391304348\n",
            "False Positive Rate: 0.043478260869565216\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9393939393939394\n",
            "precision: 0.9767441860465116\n",
            "recall: 0.8936170212765957\n",
            "F: 0.9333333333333332\n",
            "specificity: 0.9807692307692307\n",
            "False Positive Rate: 0.019230769230769232\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.8737373737373737\n",
            "precision: 0.808\n",
            "recall: 0.9901960784313726\n",
            "F: 0.8898678414096917\n",
            "specificity: 0.75\n",
            "False Positive Rate: 0.25\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.9797979797979798\n",
            "precision: 0.9885057471264368\n",
            "recall: 0.9662921348314607\n",
            "F: 0.9772727272727273\n",
            "specificity: 0.9908256880733946\n",
            "False Positive Rate: 0.009174311926605505\n",
            "\n",
            "----------AVERAGE ACCURACY 0.9293690675600225  ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.01  ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9296482412060302\n",
            "precision: 1.0\n",
            "recall: 0.8613861386138614\n",
            "F: 0.9255319148936171\n",
            "specificity: 1.0\n",
            "False Positive Rate: 0.0\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9343434343434344\n",
            "precision: 0.9603960396039604\n",
            "recall: 0.9150943396226415\n",
            "F: 0.9371980676328503\n",
            "specificity: 0.9565217391304348\n",
            "False Positive Rate: 0.043478260869565216\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9393939393939394\n",
            "precision: 0.9767441860465116\n",
            "recall: 0.8936170212765957\n",
            "F: 0.9333333333333332\n",
            "specificity: 0.9807692307692307\n",
            "False Positive Rate: 0.019230769230769232\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9191919191919192\n",
            "precision: 0.8771929824561403\n",
            "recall: 0.9803921568627451\n",
            "F: 0.9259259259259259\n",
            "specificity: 0.8541666666666666\n",
            "False Positive Rate: 0.14583333333333334\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.8636363636363636\n",
            "precision: 0.7767857142857143\n",
            "recall: 0.9775280898876404\n",
            "F: 0.8656716417910447\n",
            "specificity: 0.7706422018348624\n",
            "False Positive Rate: 0.22935779816513763\n",
            "\n",
            "----------AVERAGE ACCURACY 0.9172427795543374  ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n",
            "----------LEARNING RATE:  0.1  ----------\n",
            "----------FOLD  1 ----------\n",
            "accuracy: 0.9396984924623115\n",
            "precision: 0.9587628865979382\n",
            "recall: 0.9207920792079208\n",
            "F: 0.9393939393939394\n",
            "specificity: 0.9591836734693877\n",
            "False Positive Rate: 0.04081632653061224\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "accuracy: 0.9292929292929293\n",
            "precision: 0.9693877551020408\n",
            "recall: 0.8962264150943396\n",
            "F: 0.9313725490196079\n",
            "specificity: 0.967391304347826\n",
            "False Positive Rate: 0.03260869565217391\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "accuracy: 0.9393939393939394\n",
            "precision: 0.9767441860465116\n",
            "recall: 0.8936170212765957\n",
            "F: 0.9333333333333332\n",
            "specificity: 0.9807692307692307\n",
            "False Positive Rate: 0.019230769230769232\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "accuracy: 0.9191919191919192\n",
            "precision: 0.8771929824561403\n",
            "recall: 0.9803921568627451\n",
            "F: 0.9259259259259259\n",
            "specificity: 0.8541666666666666\n",
            "False Positive Rate: 0.14583333333333334\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "accuracy: 0.8484848484848485\n",
            "precision: 0.7565217391304347\n",
            "recall: 0.9775280898876404\n",
            "F: 0.8529411764705881\n",
            "specificity: 0.7431192660550459\n",
            "False Positive Rate: 0.25688073394495414\n",
            "\n",
            "----------AVERAGE ACCURACY 0.9152124257651895  ----------\n",
            "\n",
            "---------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}