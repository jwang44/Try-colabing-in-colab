{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECSE01_2_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/orthopedic_patients_new_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NkwhApnnJk"
      },
      "source": [
        "# ECSE 551 Mini-project 1\n",
        "*Group 10: Junhao Wang, Yinan Zhou, and Ruilin Ji*\n",
        "\n",
        "This notebook is dedicated for the **Orthopedic patients dataset**, including the model, cross validation, and various experiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3nM6IIOBf0A"
      },
      "source": [
        "## Start here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oskj54Fv8eGB",
        "outputId": "ad707089-3e4c-4966-f102-79453e0d2ab6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c74abf-bc42-4764-8df9-a08c23843da1"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFoqVsWOP14"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1gREIMPzw7M"
      },
      "source": [
        "## Orthopedic Patients Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc7bhCtyW17b"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('orthopedic_patients.csv')\n",
        "original_data = df.to_numpy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybt1JT3h0JpU"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate')\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData, df['Class']))\r\n",
        "# np.savetxt('normalized_orthopedic_patients.csv', NorPatientData, delimiter=',')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oDHjN7u0rbT"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHfVd9v2elN"
      },
      "source": [
        "# new feature\r\n",
        "NewF = newfeature(df.pelvic_incidence, df.sacral_slope)\r\n",
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df['Class']))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrl86Dhy9jy"
      },
      "source": [
        "# sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self):#,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    pass\n",
        "    \n",
        "  # training\n",
        "  def fit(self,X_train,y_train,learning_rate):\n",
        "    #n,m = np.shape(self.X_train)\n",
        "    n,m = np.shape(X_train)  \n",
        "    wk = np.ones([m+1,1]) # wk weights, initialized with 1\n",
        "    wk1 = np.zeros([m+1,1])# wk+1 weights,initialized with 0          \n",
        "    itrnum = 500       # max number of iterations \n",
        "    e = 0.001\n",
        "    der = 0\n",
        "    for k in range(0,itrnum):\n",
        "      for i in range(0,n):\n",
        "        #xi = self.X_train[i].T\n",
        "        xi = X_train[i].T\n",
        "        x0 = np.array([1])\n",
        "        xi = np.concatenate((xi, x0),axis = 0)\n",
        "        #yi = self.y_train[i]\n",
        "        yi = y_train[i]\n",
        "        der = der-xi*(yi-sigmoid(np.matmul(wk[:,0].T,xi))) # take derivative w.r.t w\n",
        "      #wk1[:,0] = wk[:,0]-self.learning_rate*der       # update rule\n",
        "      wk1[:,0] = wk[:,0]-learning_rate*der       # update rule\n",
        "      if (np.linalg.norm(wk1[:,0]-wk[:,0]))**2<e:         \n",
        "        break \n",
        "      else:\n",
        "        wk = wk1.copy()\n",
        "    return wk1\n",
        "  \n",
        "  # validation\n",
        "  def predict(self,w,X_test):\n",
        "    #n,m = np.shape(self.X_test)\n",
        "    n,m = np.shape(X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      #xi = self.X_test[i].T\n",
        "      xi = X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self,y_test,y_predict):\n",
        "    #y_predict = self.predict(X_test)\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    '''for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1'''\n",
        "    for i in range(n):\n",
        "      if  y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1    \n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accu_trains = []\n",
        "    accu_tests = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      model = Logistic_regression()\n",
        "      w = model.fit(X_train, y_train, lr)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "\n",
        "      print(\"----Train----\")\n",
        "      y_predict_train = model.predict(w, X_train)\n",
        "      accu_train = model.Accu_eval(y_train, y_predict_train)\n",
        "      accu_trains.append(accu_train)\n",
        "\n",
        "      print(\"----Validation----\")\n",
        "      y_predict_test = model.predict(w, X_test)\n",
        "      accu_test = model.Accu_eval(y_test, y_predict_test)\n",
        "      accu_tests.append(accu_test)\n",
        "\n",
        "    return np.mean(accu_trains), np.mean(accu_tests)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27f2149b-8219-4056-e7e4-6628436d8284"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 5) # different learning rates to try\n",
        "cv = Cross_validation(10) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8315412186379928\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8422939068100358\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.7885304659498208\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7419354838709677\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8136200716845878\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7956989247311828\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8207885304659498\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8100358422939068\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8143369175627241 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7967741935483871 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0001 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8422939068100358\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8387096774193549\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8422939068100358\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.7670250896057348\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.7992831541218638\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8064516129032258\n",
            "\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.7741935483870968\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.6810035842293907\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.7096774193548387\n",
            "\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.7921146953405018\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.8709677419354839\n",
            "\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8279569892473119\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.9032258064516129\n",
            "\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.7132616487455197\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.6774193548387096\n",
            "\n",
            "---------------TRAIN AVERAGE ACCURACY 0.7867383512544802 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.7645161290322581 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.001 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.6738351254480287\n",
            "\n",
            "----Validation----\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1b48d5205712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------LEARNING RATE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0maccu_train_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu_val_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------TRAIN AVERAGE ACCURACY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu_train_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------VALIDATION AVERAGE ACCURACY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu_val_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-d79755d5fe3e>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(self, Xs, ys, lr)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----Validation----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0my_predict_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0maccu_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccu_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m       \u001b[0maccu_tests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccu_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-942f76551faa>\u001b[0m in \u001b[0;36mAccu_eval\u001b[0;34m(self, y_test, y_predict)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mTN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTvS3gB7C-_Y"
      },
      "source": [
        "## Experiment with different features\n",
        "\n",
        "During the experiment on different learning rates, we found that the best learning rate is **0.0001**, so we use this learning rate for our experiment with different feature selections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e45e5e-e3eb-4705-a541-8776f161af45"
      },
      "source": [
        "lr = 0.0001\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.3548387096774194\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3225806451612903\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.3346774193548387\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.4032258064516129\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.35080645161290325\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3387096774193548\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.3629032258064516\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.2903225806451613\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.3387096774193548\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3870967741935484\n",
            "\n",
            "----------AVERAGE ACCURACY 0.3483870967741935 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726f3297-e9f1-4978-a84a-197c30512601"
      },
      "source": [
        "lr = 0.0001\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.3548387096774194\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3387096774193548\n",
            "\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.3629032258064516\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3064516129032258\n",
            "\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.35080645161290325\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3548387096774194\n",
            "\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.3387096774193548\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.4032258064516129\n",
            "\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.35080645161290325\n",
            "\n",
            "----Validation----\n",
            "accuracy: 0.3548387096774194\n",
            "\n",
            "----------AVERAGE ACCURACY 0.3516129032258065 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AA1V0Qm-jBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "776dcbd6-93c7-499c-ce8b-4404a45a5b6b"
      },
      "source": [
        "lr = 0.0001\n",
        "cv = Cross_validation(5) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew_del)\n",
        "print(\"----------Using normalized features, with new features, and deleted highly-corelated features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY\", accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-be4c5a05e7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 5-fold cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNorDatasetNew_del\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------Using normalized features, with new features, and deleted highly-corelated features----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccu_avg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu_avg_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NorDatasetNew_del' is not defined"
          ]
        }
      ]
    }
  ]
}