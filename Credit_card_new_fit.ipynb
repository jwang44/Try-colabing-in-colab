{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_card_new_fit.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/Credit_card_new_fit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NkwhApnnJk"
      },
      "source": [
        "# ECSE 551 Mini-project 1\n",
        "*Group 10: Junhao Wang, Yinan Zhou, and Ruilin Ji*\n",
        "\n",
        "This notebook is dedicated for the **Credit card dataset**, including the model, cross validation, and various experiments. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeEmvASNOp83"
      },
      "source": [
        "## Start here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGuRPcn_IsKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e0c7c0-0231-45d2-f934-1a0fae06e23f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacb9245-46fa-4333-e15a-1948c92a53b0"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNizIZXIrdM"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_w-5Z0sMsJ"
      },
      "source": [
        "## Credit Card Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXiM3pnF5j-2"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "original_data = df.to_numpy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHo1NiB4xWr"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate') # no class column\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData,df.iloc[:,-1]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kzCB3F5uWL"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyg90-iG5vCB"
      },
      "source": [
        "NewF1 = newfeature(df.V3, df.V7)\r\n",
        "NewF2 = newfeature(df.V11, df.V12)\r\n",
        "NewF3 = newfeature(df.V12, df.V16)\r\n",
        "NewF4 = newfeature(df.V16, df.V17)\r\n",
        "NewF5 = newfeature(df.V16, df.V18)\r\n",
        "NewF6 = newfeature(df.V17, df.V18)\r\n",
        "NewF7 = df.iloc[:,0]              # initialize new feature 7 using 1st feature\r\n",
        "NewF8 = newfeature(df.V3, df.V12)       # multiply features of most importance\r\n",
        "n_row,n_col = np.shape(NorData)\r\n",
        "NewFSq = np.zeros(n_row)            # initialize new features using 0s\r\n",
        "for col in range(n_col):\r\n",
        "  # new feature 7: multiplying all features\r\n",
        "  if col>0:\r\n",
        "    NewF7 = newfeature(NewF7,df.iloc[:,col])\r\n",
        "  # new feature 8-: square all columns\r\n",
        "  new = newfeature(df.iloc[:,col],df.iloc[:,col]) # square feature\r\n",
        "  NewFSq = np.column_stack((NewFSq,new))\r\n",
        "\r\n",
        "NewFSq = np.delete(NewFSq,0,1)\r\n",
        "# new feature\r\n",
        "NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6,NewF7,NewF8))\r\n",
        "# NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMYL_506R_G"
      },
      "source": [
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df.iloc[:,-1]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1X71amBOCtA"
      },
      "source": [
        " # sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self):#,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    pass\n",
        "    \n",
        "  # train\n",
        "  def fit(self, X_train, y_train, learning_rate):\n",
        "    # X_train: training features, y_train: training labels\n",
        "    n, m = np.shape(X_train)  # n samples, m features\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    w = np.ones([m+1, 1]) # features + 1\n",
        "    dummy_feature = np.ones([n, 1])\n",
        "    X = np.concatenate((X_train, dummy_feature), axis=1) # n samples, m+1 features\n",
        "    # max iteration allowed\n",
        "    max_iter = 5000 \n",
        "    for i in range(max_iter):\n",
        "      y_predict = sigmoid(np.matmul(X, w))  # n * 1\n",
        "      grad = -np.matmul(X.T, (y_train - y_predict))  # m+1 * 1\n",
        "      w = w - learning_rate * grad\n",
        "      if np.linalg.norm(learning_rate * grad) < 0.001:\n",
        "        print(\"Early stop at iteration: \", i+1)\n",
        "        break\n",
        "    return w\n",
        "  \n",
        "  # validation\n",
        "  def predict(self,w,X_test):\n",
        "    #n,m = np.shape(self.X_test)\n",
        "    n,m = np.shape(X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      #xi = self.X_test[i].T\n",
        "      xi = X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self,y_test,y_predict):\n",
        "    #y_predict = self.predict(X_test)\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    '''for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1'''\n",
        "    for i in range(n):\n",
        "      if  y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1    \n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    # print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ43SMNlZwiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87403721-ba8f-4451-fb1a-9949a5c8aeb6"
      },
      "source": [
        "# figure out which feature is of the most importance\r\n",
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels\r\n",
        "w = model.fit(X,y,learning_rate=0.001)\r\n",
        "print(w)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  2408\n",
            "[[ 1.55081845]\n",
            " [ 1.0933058 ]\n",
            " [-4.03375893]\n",
            " [ 1.94595797]\n",
            " [ 1.26066542]\n",
            " [-1.71833441]\n",
            " [-0.70288352]\n",
            " [-2.77580802]\n",
            " [-0.22065837]\n",
            " [-2.45386379]\n",
            " [ 0.14203829]\n",
            " [-4.5782209 ]\n",
            " [-0.14985273]\n",
            " [-1.1939046 ]\n",
            " [-0.61306626]\n",
            " [-0.16584005]\n",
            " [ 1.27379042]\n",
            " [ 1.29107767]\n",
            " [-0.01049958]\n",
            " [-1.0596618 ]\n",
            " [-0.4266146 ]\n",
            " [ 1.70847384]\n",
            " [ 0.45035064]\n",
            " [-0.41407882]\n",
            " [-0.48774679]\n",
            " [ 0.1353532 ]\n",
            " [-0.91413545]\n",
            " [ 0.12909789]\n",
            " [ 1.2530027 ]\n",
            " [ 4.96807387]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accu_trains = []\n",
        "    accu_tests = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      model = Logistic_regression()\n",
        "      w = model.fit(X_train, y_train, lr)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "\n",
        "      print(\"----Train----\")\n",
        "      y_predict_train = model.predict(w, X_train)\n",
        "      accu_train = model.Accu_eval(y_train, y_predict_train)\n",
        "      accu_trains.append(accu_train)\n",
        "\n",
        "      print(\"----Validation----\")\n",
        "      y_predict_test = model.predict(w, X_test)\n",
        "      accu_test = model.Accu_eval(y_test, y_predict_test)\n",
        "      accu_tests.append(accu_test)\n",
        "\n",
        "    return np.mean(accu_trains), np.mean(accu_tests)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKbtaUO53F00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794244ae-ecfc-4f24-a12e-b44aa6328923"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9349046015712682\n",
            "----Validation----\n",
            "accuracy: 0.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8262331838565022\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8778026905829597\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.844170403587444\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8340807174887892\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8789237668161435\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8910240924441224 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8950606060606061 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9337822671156004\n",
            "----Validation----\n",
            "accuracy: 0.89\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8262331838565022\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9316143497757847\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8307174887892377\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.820627802690583\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8980867468909322 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8950606060606059 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9326599326599326\n",
            "----Validation----\n",
            "accuracy: 0.89\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.827354260089686\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8374439461883408\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8733183856502242\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8329596412556054\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8486547085201793\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8172645739910314\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8753287735350515 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8708181818181819 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8507295173961841\n",
            "----Validation----\n",
            "accuracy: 0.81\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8778026905829597\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8385650224215246\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.875560538116592\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.82847533632287\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8318385650224215\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8497757847533632\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8161434977578476\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8620908889593493 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8527171717171717 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9326599326599326\n",
            "----Validation----\n",
            "accuracy: 0.89\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8396860986547086\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8778026905829597\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.82847533632287\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8486547085201793\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8958444686023161 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8849595959595961 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9326599326599326\n",
            "----Validation----\n",
            "accuracy: 0.89\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8251121076233184\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8789237668161435\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8363228699551569\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.82847533632287\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8932659932659932 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8940505050505051 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9326599326599326\n",
            "----Validation----\n",
            "accuracy: 0.89\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8251121076233184\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8396860986547086\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.82847533632287\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8733183856502242\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8329596412556054\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9237668161434978\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8836247376606121 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.883949494949495 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8473625140291807\n",
            "----Validation----\n",
            "accuracy: 0.81\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9237668161434978\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8766816143497758\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.82847533632287\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.874439461883408\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8329596412556054\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8475336322869955\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8161434977578476\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8703864756181646 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8607979797979798 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9326599326599326\n",
            "----Validation----\n",
            "accuracy: 0.89\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.827354260089686\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8329596412556054\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8161434977578476\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8971897600821368 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8991010101010101 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8473625140291807\n",
            "----Validation----\n",
            "accuracy: 0.81\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.827354260089686\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8396860986547086\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8766816143497758\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8295964125560538\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8161434977578476\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8749828881742185 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8688787878787879 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd04abf-9aef-420b-b5f7-9e7afe6bdd63"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "Early stop at iteration:  1526\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8877665544332211\n",
            "----Validation----\n",
            "accuracy: 0.85\n",
            "Early stop at iteration:  1513\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1481\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.8282828282828283\n",
            "Early stop at iteration:  1589\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8946188340807175\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1536\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "Early stop at iteration:  1482\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8923766816143498\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "Early stop at iteration:  1535\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8912556053811659\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1581\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8878923766816144\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1523\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8845291479820628\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1524\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8878923766816144\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8901219469231428 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8839898989898989 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "Early stop at iteration:  1431\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.936026936026936\n",
            "----Validation----\n",
            "accuracy: 0.9\n",
            "Early stop at iteration:  1491\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1437\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9394618834080718\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1448\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9327354260089686\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1362\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1455\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1425\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9349775784753364\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1452\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1483\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1451\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9322798236475366 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9263636363636364 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "Early stop at iteration:  1753\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9539842873176206\n",
            "----Validation----\n",
            "accuracy: 0.91\n",
            "Early stop at iteration:  1843\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1713\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1847\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1789\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1797\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1879\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1733\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1764\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1876\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9527975318707755 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9445353535353535 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "Early stop at iteration:  2404\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9640852974186308\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2484\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "Early stop at iteration:  2182\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2467\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2518\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2432\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2521\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2450\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2434\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2580\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9633367808629393 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9545959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "Early stop at iteration:  2653\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663299663299664\n",
            "----Validation----\n",
            "accuracy: 0.96\n",
            "Early stop at iteration:  2617\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2397\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2765\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2937\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2538\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2681\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2724\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2592\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2886\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9656912925971222 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9576161616161617 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "Early stop at iteration:  2533\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2171\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2071\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2383\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2503\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2211\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2298\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2368\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2247\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2940\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9671488175225097 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9545959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "Early stop at iteration:  2210\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  1754\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1711\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1902\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2089\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2072\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2034\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1939\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1884\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2659\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9675972480157832 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9556060606060607 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "Early stop at iteration:  2825\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2045\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1701\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1587\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2368\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  3672\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2748\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2094\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1989\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3424\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9677093556391017 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9566161616161615 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506172839506173\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.945067264573991\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9505550019376626 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9414949494949495 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9270482603815937\n",
            "----Validation----\n",
            "accuracy: 0.9\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9405829596412556\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9394618834080718\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9492070681906257 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9455555555555556 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzMkjdTuHXfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae6d150-978a-44f5-d4ae-686d0513cb71"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\r\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\r\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\r\n",
        "for lr in lrs:\r\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\r\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\r\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\r\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\r\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "Early stop at iteration:  1706\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8821548821548821\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "Early stop at iteration:  1724\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8856502242152466\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1622\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8901345291479821\n",
            "----Validation----\n",
            "accuracy: 0.797979797979798\n",
            "Early stop at iteration:  1738\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8923766816143498\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1690\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8834080717488789\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1641\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8834080717488789\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "Early stop at iteration:  1655\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "Early stop at iteration:  1690\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8867713004484304\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "Early stop at iteration:  1726\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8856502242152466\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "Early stop at iteration:  1556\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8800448430493274\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "---------------TRAIN AVERAGE ACCURACY 0.885861228125802 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8778585858585858 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "Early stop at iteration:  1636\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9315375982042648\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "Early stop at iteration:  1614\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1607\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9316143497757847\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "Early stop at iteration:  1628\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1648\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1621\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1625\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1646\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9316143497757847\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1630\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1695\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9295887373989018 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9243131313131314 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "Early stop at iteration:  2028\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551066217732884\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "Early stop at iteration:  1929\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1843\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1914\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1959\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1981\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2028\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9517937219730942\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1987\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2076\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2004\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9533581958096157 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9445050505050505 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "Early stop at iteration:  2544\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9640852974186308\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "Early stop at iteration:  2411\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2407\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2759\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2493\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2426\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2340\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2392\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2838\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2508\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9623278122530738 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9535959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "Early stop at iteration:  2653\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652076318742986\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "Early stop at iteration:  2507\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3128\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2871\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2498\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2473\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2529\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2666\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  3389\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2506\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9656911667748739 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9566262626262626 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "Early stop at iteration:  2458\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9696969696969697\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "Early stop at iteration:  2434\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3159\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2602\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2322\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2205\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "Early stop at iteration:  2355\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2324\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  3832\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9719730941704036\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2348\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9673732844136431 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9566262626262626 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "Early stop at iteration:  3342\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9696969696969697\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "Early stop at iteration:  3661\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2929\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9719730941704036\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  3110\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2977\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2650\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "Early stop at iteration:  3066\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2685\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9742152466367713\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  3168\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9691670063867374 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9556161616161616 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9730941704035875\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9673730327691464 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9535858585858585 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9450056116722784\n",
            "----Validation----\n",
            "accuracy: 0.96\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9327354260089686\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9513391261896494 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9263030303030304 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9382716049382716\n",
            "----Validation----\n",
            "accuracy: 0.96\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9103139013452914\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9501051873996568 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9353939393939396 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tX0BHqIfsy"
      },
      "source": [
        "## Experiment with different features\n",
        "\n",
        "During the experiment on different learning rates, we found that the best learning rates for the three sets of features: \n",
        "\n",
        "* Original dataset: **0.0359**\n",
        "\n",
        "* Normalized dataset: **0.0006**\n",
        "\n",
        "* Normalized dataset with new features: **0.0006 or 0.0017**\n",
        "\n",
        "For displaying the model accuracies more clearly, in this section\n",
        "we train a model on each dataset using its best learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLeXmXRhjO_m",
        "outputId": "9da62a49-ec99-4a8a-958b-fa5d40381b6c"
      },
      "source": [
        "lr = 0.0359\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "print(\"----------Using orginal data, no normalization, no new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using orginal data, no normalization, no new features----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9259259259259259\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8408071748878924\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8721973094170403\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8654708520179372\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8452914798206278\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8621076233183856\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9260089686098655\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8710762331838565\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9192825112107623\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------AVERAGE ACCURACY: train- 0.8855298123235343  vs. validation- 0.8889696969696971 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85dfc46-713d-454e-a278-0da1f519a259"
      },
      "source": [
        "lr = 0.0006\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n",
            "Early stop at iteration:  2593\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652076318742986\n",
            "----Validation----\n",
            "accuracy: 0.97\n",
            "Early stop at iteration:  2721\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2591\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2741\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2478\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "Early stop at iteration:  2518\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2932\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2542\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2654\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2868\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------AVERAGE ACCURACY: train- 0.9655790591515554  vs. validation- 0.9586161616161617 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979b10dd-bc73-4f5c-a4b6-55a4b8714d69"
      },
      "source": [
        "lr = 0.0017\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "Early stop at iteration:  2344\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.96\n",
            "Early stop at iteration:  4116\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9719730941704036\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2444\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2524\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2509\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2517\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2401\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2856\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2557\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2127\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------AVERAGE ACCURACY: train- 0.9673730327691462  vs. validation- 0.9555959595959594 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSYRgbudHMP"
      },
      "source": [
        "## Measure the run time\n",
        "See whether the model converges faster on normalized data than on original data. This is measured by training the model and time it. This part stands on its own, and is not related to any of the above process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv2EzGJkxYT3"
      },
      "source": [
        "###Comparison on original and normalized dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxgZUMXvxdvA"
      },
      "source": [
        "####Using the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKO2U5gAxdvB"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(original_data)\n",
        "X = original_data[:, :-1]  # features\n",
        "y = original_data[:, -1]   # labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKriES7le0Pz",
        "outputId": "5d391d9d-ae20-4599-fa4f-2eb560eeee82"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.00001)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 426 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp-gFmFkxdvB",
        "outputId": "7f137bf2-74ab-47ca-c716-784ebddd2ac2"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 490 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoZ_UQERkn5U",
        "outputId": "eebd8094-4a81-4812-ea6e-91ae2a642917"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.01)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 497 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADUOGncyxdvC"
      },
      "source": [
        "####Using normalized dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URzNCZXyxdvC"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrPg4E1ti1iV",
        "outputId": "03c6bfc6-790b-424d-c4aa-784b1cb6f36c"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.00001)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "Early stop at iteration:  1568\n",
            "10 loops, best of 3: 140 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyEBRlUCxdvD",
        "outputId": "f14915bc-92ae-4b1a-f9bc-98bdb139444c"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  2408\n",
            "Early stop at iteration:  2408\n",
            "Early stop at iteration:  2408\n",
            "Early stop at iteration:  2408\n",
            "1 loop, best of 3: 211 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44s_vMSPlyNs",
        "outputId": "2967b316-bed4-47aa-e60c-0c075984a203"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.01)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "Early stop at iteration:  2110\n",
            "10 loops, best of 3: 190 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTl5SSvzSR8p"
      },
      "source": [
        "### Scanning more lrs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKC_xyrBEdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "851692e0-c58d-4843-d0fc-218685dc2136"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels\n",
        "\n",
        "lrs = np.logspace(-4, -1, 20) # different learning rates to try\n",
        "times = []\n",
        "\n",
        "for lr in lrs:\n",
        "  model = Logistic_regression()\n",
        "  print(\"learning rate: \", lr)\n",
        "  t1 = time.time()\n",
        "  w = model.fit(X, y, learning_rate=lr)\n",
        "  t2 = time.time()\n",
        "  print(\"time: \", t2-t1)\n",
        "  times.append(t2-t1)\n",
        "\n",
        "plt.plot(times)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate:  0.0001\n",
            "Early stop at iteration:  2012\n",
            "time:  0.18056988716125488\n",
            "learning rate:  0.0001438449888287663\n",
            "Early stop at iteration:  2245\n",
            "time:  0.20694851875305176\n",
            "learning rate:  0.00020691380811147902\n",
            "Early stop at iteration:  2466\n",
            "time:  0.23728537559509277\n",
            "learning rate:  0.00029763514416313193\n",
            "Early stop at iteration:  2631\n",
            "time:  0.23705768585205078\n",
            "learning rate:  0.00042813323987193956\n",
            "Early stop at iteration:  2655\n",
            "time:  0.24550604820251465\n",
            "learning rate:  0.0006158482110660267\n",
            "Early stop at iteration:  2568\n",
            "time:  0.23929977416992188\n",
            "learning rate:  0.0008858667904100823\n",
            "Early stop at iteration:  2450\n",
            "time:  0.22341465950012207\n",
            "learning rate:  0.0012742749857031334\n",
            "Early stop at iteration:  2320\n",
            "time:  0.24155640602111816\n",
            "learning rate:  0.0018329807108324356\n",
            "Early stop at iteration:  2180\n",
            "time:  0.21182847023010254\n",
            "learning rate:  0.0026366508987303583\n",
            "Early stop at iteration:  2041\n",
            "time:  0.1935577392578125\n",
            "learning rate:  0.00379269019073225\n",
            "Early stop at iteration:  1925\n",
            "time:  0.17540931701660156\n",
            "learning rate:  0.005455594781168515\n",
            "Early stop at iteration:  1885\n",
            "time:  0.1663212776184082\n",
            "learning rate:  0.007847599703514606\n",
            "Early stop at iteration:  1985\n",
            "time:  0.20523285865783691\n",
            "learning rate:  0.011288378916846883\n",
            "Early stop at iteration:  2168\n",
            "time:  0.1922001838684082\n",
            "learning rate:  0.01623776739188721\n",
            "time:  0.48366308212280273\n",
            "learning rate:  0.023357214690901212\n",
            "time:  0.4680328369140625\n",
            "learning rate:  0.03359818286283781\n",
            "time:  0.45626378059387207\n",
            "learning rate:  0.04832930238571752\n",
            "time:  0.47734928131103516\n",
            "learning rate:  0.06951927961775606\n",
            "time:  0.4559485912322998\n",
            "learning rate:  0.1\n",
            "time:  0.5061538219451904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1bded71898>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}