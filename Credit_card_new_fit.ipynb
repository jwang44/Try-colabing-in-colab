{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_card_new_fit.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/Credit_card_new_fit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NkwhApnnJk"
      },
      "source": [
        "# ECSE 551 Mini-project 1\n",
        "*Group 10: Junhao Wang, Yinan Zhou, and Ruilin Ji*\n",
        "\n",
        "This notebook is dedicated for the **Credit card dataset**, including the model, cross validation, and various experiments. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeEmvASNOp83"
      },
      "source": [
        "## Start here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGuRPcn_IsKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb601cd3-528b-4fe5-923b-a8fea1537d83"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b023ce-ae96-4ced-a116-38905e5b8add"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNizIZXIrdM"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_w-5Z0sMsJ"
      },
      "source": [
        "## Credit Card Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXiM3pnF5j-2"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "original_data = df.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHo1NiB4xWr"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate') # no class column\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData,df.iloc[:,-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kzCB3F5uWL"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyg90-iG5vCB"
      },
      "source": [
        "NewF1 = newfeature(df.V3, df.V7)\r\n",
        "NewF2 = newfeature(df.V11, df.V12)\r\n",
        "NewF3 = newfeature(df.V12, df.V16)\r\n",
        "NewF4 = newfeature(df.V16, df.V17)\r\n",
        "NewF5 = newfeature(df.V16, df.V18)\r\n",
        "NewF6 = newfeature(df.V17, df.V18)\r\n",
        "NewF7 = df.iloc[:,0]              # initialize new feature 7 using 1st feature\r\n",
        "NewF8 = newfeature(df.V3, df.V12)       # multiply features of most importance\r\n",
        "n_row,n_col = np.shape(NorData)\r\n",
        "NewFSq = np.zeros(n_row)            # initialize new features using 0s\r\n",
        "for col in range(n_col):\r\n",
        "  # new feature 7: multiplying all features\r\n",
        "  if col>0:\r\n",
        "    NewF7 = newfeature(NewF7,df.iloc[:,col])\r\n",
        "  # new feature 8-: square all columns\r\n",
        "  new = newfeature(df.iloc[:,col],df.iloc[:,col]) # square feature\r\n",
        "  NewFSq = np.column_stack((NewFSq,new))\r\n",
        "\r\n",
        "NewFSq = np.delete(NewFSq,0,1)\r\n",
        "# new feature\r\n",
        "NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6,NewF7,NewF8))\r\n",
        "# NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMYL_506R_G"
      },
      "source": [
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df.iloc[:,-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1X71amBOCtA"
      },
      "source": [
        " # sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self):#,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    pass\n",
        "    \n",
        "  # train\n",
        "  def fit(self, X_train, y_train, learning_rate):\n",
        "    # X_train: training features, y_train: training labels\n",
        "    n, m = np.shape(X_train)  # n samples, m features\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    w = np.ones([m+1, 1]) # features + 1\n",
        "    dummy_feature = np.ones([n, 1])\n",
        "    X = np.concatenate((X_train, dummy_feature), axis=1) # n samples, m+1 features\n",
        "    # max iteration allowed\n",
        "    max_iter = 5000 \n",
        "    for i in range(max_iter):\n",
        "      y_predict = sigmoid(np.matmul(X, w))  # n * 1\n",
        "      grad = -np.matmul(X.T, (y_train - y_predict))  # m+1 * 1\n",
        "      w = w - learning_rate * grad\n",
        "      if np.linalg.norm(learning_rate * grad) < 0.001:\n",
        "        print(\"Early stop at iteration: \", i+1)\n",
        "        break\n",
        "    return w\n",
        "  \n",
        "  # validation\n",
        "  def predict(self,w,X_test):\n",
        "    #n,m = np.shape(self.X_test)\n",
        "    n,m = np.shape(X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      #xi = self.X_test[i].T\n",
        "      xi = X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self,y_test,y_predict):\n",
        "    #y_predict = self.predict(X_test)\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    '''for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1'''\n",
        "    for i in range(n):\n",
        "      if  y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1    \n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    # print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ43SMNlZwiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1350b0-3fa7-4225-9267-35fbfeba8da9"
      },
      "source": [
        "# figure out which feature is of the most importance\r\n",
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels\r\n",
        "w = model.fit(X,y,learning_rate=0.001)\r\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  2408\n",
            "[[ 1.55081845]\n",
            " [ 1.0933058 ]\n",
            " [-4.03375893]\n",
            " [ 1.94595797]\n",
            " [ 1.26066542]\n",
            " [-1.71833441]\n",
            " [-0.70288352]\n",
            " [-2.77580802]\n",
            " [-0.22065837]\n",
            " [-2.45386379]\n",
            " [ 0.14203829]\n",
            " [-4.5782209 ]\n",
            " [-0.14985273]\n",
            " [-1.1939046 ]\n",
            " [-0.61306626]\n",
            " [-0.16584005]\n",
            " [ 1.27379042]\n",
            " [ 1.29107767]\n",
            " [-0.01049958]\n",
            " [-1.0596618 ]\n",
            " [-0.4266146 ]\n",
            " [ 1.70847384]\n",
            " [ 0.45035064]\n",
            " [-0.41407882]\n",
            " [-0.48774679]\n",
            " [ 0.1353532 ]\n",
            " [-0.91413545]\n",
            " [ 0.12909789]\n",
            " [ 1.2530027 ]\n",
            " [ 4.96807387]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accu_trains = []\n",
        "    accu_tests = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      model = Logistic_regression()\n",
        "      w = model.fit(X_train, y_train, lr)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "\n",
        "      print(\"----Train----\")\n",
        "      y_predict_train = model.predict(w, X_train)\n",
        "      accu_train = model.Accu_eval(y_train, y_predict_train)\n",
        "      accu_trains.append(accu_train)\n",
        "\n",
        "      print(\"----Validation----\")\n",
        "      y_predict_test = model.predict(w, X_test)\n",
        "      accu_test = model.Accu_eval(y_test, y_predict_test)\n",
        "      accu_tests.append(accu_test)\n",
        "\n",
        "    return np.mean(accu_trains), np.mean(accu_tests)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKbtaUO53F00"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd04abf-9aef-420b-b5f7-9e7afe6bdd63"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "Early stop at iteration:  1526\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8877665544332211\n",
            "----Validation----\n",
            "accuracy: 0.85\n",
            "Early stop at iteration:  1513\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1481\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.8282828282828283\n",
            "Early stop at iteration:  1589\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8946188340807175\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1536\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "Early stop at iteration:  1482\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8923766816143498\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "Early stop at iteration:  1535\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8912556053811659\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1581\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8878923766816144\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1523\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8845291479820628\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1524\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8878923766816144\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8901219469231428 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8839898989898989 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "Early stop at iteration:  1431\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.936026936026936\n",
            "----Validation----\n",
            "accuracy: 0.9\n",
            "Early stop at iteration:  1491\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1437\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9394618834080718\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1448\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9327354260089686\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1362\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1455\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1425\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9349775784753364\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1452\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1483\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1451\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9322798236475366 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9263636363636364 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "Early stop at iteration:  1753\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9539842873176206\n",
            "----Validation----\n",
            "accuracy: 0.91\n",
            "Early stop at iteration:  1843\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1713\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1847\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1789\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1797\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1879\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1733\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1764\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1876\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9527975318707755 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9445353535353535 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "Early stop at iteration:  2404\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9640852974186308\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2484\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "Early stop at iteration:  2182\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2467\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2518\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2432\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2521\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2450\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2434\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2580\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9633367808629393 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9545959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "Early stop at iteration:  2653\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663299663299664\n",
            "----Validation----\n",
            "accuracy: 0.96\n",
            "Early stop at iteration:  2617\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2397\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2765\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2937\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2538\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2681\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2724\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2592\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2886\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9656912925971222 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9576161616161617 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "Early stop at iteration:  2533\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2171\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2071\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2383\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2503\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2211\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2298\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2368\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2247\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2940\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9671488175225097 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9545959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "Early stop at iteration:  2210\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  1754\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1711\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1902\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2089\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2072\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2034\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1939\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1884\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2659\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9675972480157832 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9556060606060607 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "Early stop at iteration:  2825\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2045\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1701\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1587\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2368\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  3672\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2748\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2094\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1989\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3424\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9677093556391017 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9566161616161615 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506172839506173\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.945067264573991\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9505550019376626 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9414949494949495 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9270482603815937\n",
            "----Validation----\n",
            "accuracy: 0.9\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9405829596412556\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9394618834080718\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9492070681906257 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9455555555555556 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzMkjdTuHXfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fc2c59-5d8b-4d46-dc25-a1972e6f500b"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\r\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\r\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\r\n",
        "for lr in lrs:\r\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\r\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\r\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\r\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\r\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "Early stop at iteration:  1705\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8866442199775533\n",
            "----Validation----\n",
            "accuracy: 0.88\n",
            "Early stop at iteration:  1647\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8856502242152466\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "Early stop at iteration:  1693\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8822869955156951\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1717\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8867713004484304\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1573\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8800448430493274\n",
            "----Validation----\n",
            "accuracy: 0.797979797979798\n",
            "Early stop at iteration:  1717\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8867713004484304\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1669\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8834080717488789\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "Early stop at iteration:  1693\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8946188340807175\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "Early stop at iteration:  1690\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8811659192825112\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1646\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8811659192825112\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8848527628049301 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8768888888888888 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "Early stop at iteration:  1571\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9292929292929293\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "Early stop at iteration:  1605\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1627\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1684\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1620\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9349775784753364\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "Early stop at iteration:  1644\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1633\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9372197309417041\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1624\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9327354260089686\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1693\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1640\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9302611314943153 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9212929292929294 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "Early stop at iteration:  1776\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506172839506173\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  1988\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1920\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2001\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1957\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2003\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2001\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1973\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1980\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9517937219730942\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2058\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9531334772739856 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9424747474747475 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "Early stop at iteration:  2753\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.957351290684624\n",
            "----Validation----\n",
            "accuracy: 0.99\n",
            "Early stop at iteration:  2313\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2548\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2414\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2348\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2503\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2619\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2576\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2407\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2538\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9623270573195836 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9525353535353535 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "Early stop at iteration:  2754\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9629629629629629\n",
            "----Validation----\n",
            "accuracy: 0.99\n",
            "Early stop at iteration:  2498\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2566\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2692\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2517\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2762\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2829\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2955\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2581\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2638\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9653545922604219 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9565757575757574 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "Early stop at iteration:  2487\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652076318742986\n",
            "----Validation----\n",
            "accuracy: 0.99\n",
            "Early stop at iteration:  2393\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2213\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2550\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2200\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2598\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  3120\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2551\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2392\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2564\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9672606735013313 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9555656565656564 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "Early stop at iteration:  3091\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.99\n",
            "Early stop at iteration:  3072\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2957\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  3414\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1991\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  3713\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2013\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  3770\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3829\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9686062166256487 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9555656565656564 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618406285072951\n",
            "----Validation----\n",
            "accuracy: 0.99\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  3220\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9659150045547655 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9515252525252524 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.941638608305275\n",
            "----Validation----\n",
            "accuracy: 0.97\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.945067264573991\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9383408071748879\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9405829596412556\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9503297801130387 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9374040404040406 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9472502805836139\n",
            "----Validation----\n",
            "accuracy: 0.97\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9383408071748879\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9405829596412556\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9349775784753364\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9446129204350431 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9242727272727272 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tX0BHqIfsy"
      },
      "source": [
        "## Experiment with different features\n",
        "\n",
        "During the experiment on different learning rates, we found that the best learning rate is **0.0046**, so we use this learning rate for our experiment with different feature selections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLeXmXRhjO_m"
      },
      "source": [
        "lr = 0.0046\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "print(\"----------Using orginal data, no normalization, no new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7295faab-9295-4f7d-e2ab-c767191412fd"
      },
      "source": [
        "lr = 0.0046\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n",
            "Early stop at iteration:  2413\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9730639730639731\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "Early stop at iteration:  2941\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1752\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2592\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2049\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1923\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1844\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1550\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1835\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2009\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------AVERAGE ACCURACY: train- 0.9674857695037067  vs. validation- 0.9526060606060606 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfafa9fc-6233-4192-9b37-8595f65cf34b"
      },
      "source": [
        "lr = 0.00060\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "Early stop at iteration:  2571\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618406285072951\n",
            "----Validation----\n",
            "accuracy: 0.98\n",
            "Early stop at iteration:  2851\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2623\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2714\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2714\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  2571\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2706\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  3145\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2636\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2550\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------AVERAGE ACCURACY: train- 0.965802896931447  vs. validation- 0.9565858585858585 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSYRgbudHMP"
      },
      "source": [
        "## Measure the run time\n",
        "See whether the model converges faster on normalized data than on original data. This is measured by training the model and time it. This part stands on its own, and is not related to any of the above process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhONMhAxkuC7"
      },
      "source": [
        "###Comparison on Original dataset and normalized dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T-jHRpsdgHZ"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(original_data)\n",
        "X = original_data[:, :-1]  # features\n",
        "y = original_data[:, -1]   # labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ39ltUkkZJj",
        "outputId": "dd09dab0-8a46-460d-9249-1e972287e7b6"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 448 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0btaceUVd83p"
      },
      "source": [
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oePKiDuLlyNs",
        "outputId": "6b1f7480-556e-4c3c-d3f9-a071a7d5d1b0"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  2408\n",
            "Early stop at iteration:  2408\n",
            "Early stop at iteration:  2408\n",
            "Early stop at iteration:  2408\n",
            "1 loop, best of 3: 184 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCwwb-clC5m"
      },
      "source": [
        "###Using normalized features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOcmreeith4"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tP6ejB1go3G"
      },
      "source": [
        "import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "lr = [1]\r\n",
        "t = []\r\n",
        "for index in range(10):\r\n",
        "  lr.append(lr[-1]*0.1)\r\n",
        "  t1 = time.time()\r\n",
        "  model.fit(X, y, learning_rate=lr[-1])\r\n",
        "  t2 = time.time()\r\n",
        "  print(\"lr: \",lr[-1],\"time: \", t2-t1)\r\n",
        "  t.append(t2-t1)\r\n",
        "\r\n",
        "plt.plot(lr[1:],t)\r\n",
        "plt.xscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsBmIGxghil3"
      },
      "source": [
        "plt.plot(lr[1:],t)\r\n",
        "plt.xscale('log')\r\n",
        "plt.yscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTl5SSvzSR8p"
      },
      "source": [
        "## Scanning more lrs, in order to find the relation between lr and time for convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKC_xyrBEdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0a00c0a-88c1-40cf-ffa7-25898d7d58de"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels\n",
        "\n",
        "lrs = np.logspace(-4, -1, 20) # different learning rates to try\n",
        "times = []\n",
        "\n",
        "for lr in lrs:\n",
        "  model = Logistic_regression()\n",
        "  print(\"learning rate: \", lr)\n",
        "  t1 = time.time()\n",
        "  w = model.fit(X, y, learning_rate=lr)\n",
        "  t2 = time.time()\n",
        "  print(\"time: \", t2-t1)\n",
        "  times.append(t2-t1)\n",
        "\n",
        "plt.plot(times)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate:  0.0001\n",
            "Early stop at iteration:  2012\n",
            "time:  0.16172409057617188\n",
            "learning rate:  0.0001438449888287663\n",
            "Early stop at iteration:  2245\n",
            "time:  0.18435001373291016\n",
            "learning rate:  0.00020691380811147902\n",
            "Early stop at iteration:  2466\n",
            "time:  0.20900964736938477\n",
            "learning rate:  0.00029763514416313193\n",
            "Early stop at iteration:  2631\n",
            "time:  0.2175884246826172\n",
            "learning rate:  0.00042813323987193956\n",
            "Early stop at iteration:  2655\n",
            "time:  0.22005009651184082\n",
            "learning rate:  0.0006158482110660267\n",
            "Early stop at iteration:  2568\n",
            "time:  0.22574210166931152\n",
            "learning rate:  0.0008858667904100823\n",
            "Early stop at iteration:  2450\n",
            "time:  0.19501638412475586\n",
            "learning rate:  0.0012742749857031334\n",
            "Early stop at iteration:  2320\n",
            "time:  0.20213556289672852\n",
            "learning rate:  0.0018329807108324356\n",
            "Early stop at iteration:  2180\n",
            "time:  0.17310857772827148\n",
            "learning rate:  0.0026366508987303583\n",
            "Early stop at iteration:  2041\n",
            "time:  0.16673660278320312\n",
            "learning rate:  0.00379269019073225\n",
            "Early stop at iteration:  1925\n",
            "time:  0.15102386474609375\n",
            "learning rate:  0.005455594781168515\n",
            "Early stop at iteration:  1885\n",
            "time:  0.1619870662689209\n",
            "learning rate:  0.007847599703514606\n",
            "Early stop at iteration:  1985\n",
            "time:  0.1612870693206787\n",
            "learning rate:  0.011288378916846883\n",
            "Early stop at iteration:  2168\n",
            "time:  0.18913912773132324\n",
            "learning rate:  0.01623776739188721\n",
            "time:  0.4122941493988037\n",
            "learning rate:  0.023357214690901212\n",
            "time:  0.4089787006378174\n",
            "learning rate:  0.03359818286283781\n",
            "time:  0.4208061695098877\n",
            "learning rate:  0.04832930238571752\n",
            "time:  0.42267632484436035\n",
            "learning rate:  0.06951927961775606\n",
            "time:  0.4115173816680908\n",
            "learning rate:  0.1\n",
            "time:  0.40546154975891113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa280618128>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}