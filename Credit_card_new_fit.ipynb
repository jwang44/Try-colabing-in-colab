{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_card_new_fit.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/Credit_card_new_fit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NkwhApnnJk"
      },
      "source": [
        "# ECSE 551 Mini-project 1\n",
        "*Group 10: Junhao Wang, Yinan Zhou, and Ruilin Ji*\n",
        "\n",
        "This notebook is dedicated for the credit card dataset, including the model, cross validation, and various experiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeEmvASNOp83"
      },
      "source": [
        "## Start here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGuRPcn_IsKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11384d8-55a7-4ee4-9fd7-24dc738b2956"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63adbe89-27c2-4c1f-bb49-4839c350b9de"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNizIZXIrdM"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_w-5Z0sMsJ"
      },
      "source": [
        "## Credit Card Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXiM3pnF5j-2"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "original_data = df.to_numpy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHo1NiB4xWr"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate') # no class column\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData,df.iloc[:,-1]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kzCB3F5uWL"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyg90-iG5vCB"
      },
      "source": [
        "NewF1 = newfeature(df.V3, df.V7)\r\n",
        "NewF2 = newfeature(df.V11, df.V12)\r\n",
        "NewF3 = newfeature(df.V12, df.V16)\r\n",
        "NewF4 = newfeature(df.V16, df.V17)\r\n",
        "NewF5 = newfeature(df.V16, df.V18)\r\n",
        "NewF6 = newfeature(df.V17, df.V18)\r\n",
        "NewF7 = df.iloc[:,0]              # initialize new feature 7 using 1st feature\r\n",
        "n_row,n_col = np.shape(NorData)\r\n",
        "NewFSq = np.zeros(n_row)            # initialize new features using 0s\r\n",
        "for col in range(n_col):\r\n",
        "  # new feature 7: multiplying all features\r\n",
        "  if col>0:\r\n",
        "    NewF7 = newfeature(NewF7,df.iloc[:,col])\r\n",
        "  # new feature 8-: square all columns\r\n",
        "  new = newfeature(df.iloc[:,col],df.iloc[:,col]) # square feature\r\n",
        "  NewFSq = np.column_stack((NewFSq,new))\r\n",
        "\r\n",
        "NewFSq = np.delete(NewFSq,0,1)\r\n",
        "# new feature\r\n",
        "NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6,NewF7))\r\n",
        "# NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMYL_506R_G"
      },
      "source": [
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df.iloc[:,-1]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1X71amBOCtA"
      },
      "source": [
        " # sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self):#,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    pass\n",
        "    \n",
        "  # train\n",
        "  def fit(self, X_train, y_train, learning_rate):\n",
        "    n, m = np.shape(X_train)  # n samples, m features\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    w = np.ones([m+1, 1]) # features + 1\n",
        "    dummy_feature = np.ones([n, 1])\n",
        "    X = np.concatenate((X_train, dummy_feature), axis=1) # n samples, m+1 features\n",
        "    # max iteration allowed\n",
        "    max_iter = 5000 \n",
        "    for i in range(max_iter):\n",
        "      y_predict = sigmoid(np.matmul(X, w))  # n * 1\n",
        "      grad = -np.matmul(X.T, (y_train - y_predict))  # m+1 * 1\n",
        "      w = w - learning_rate * grad\n",
        "      if np.linalg.norm(learning_rate * grad) < 0.001:\n",
        "        print(\"Early stop at iteration: \", i+1)\n",
        "        break\n",
        "    return w\n",
        "  \n",
        "  # validation\n",
        "  def predict(self,w,X_test):\n",
        "    #n,m = np.shape(self.X_test)\n",
        "    n,m = np.shape(X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      #xi = self.X_test[i].T\n",
        "      xi = X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self,y_test,y_predict):\n",
        "    #y_predict = self.predict(X_test)\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    '''for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1'''\n",
        "    for i in range(n):\n",
        "      if  y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1    \n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    # print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ43SMNlZwiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ce4dd5-8d70-4e5c-93f4-1e6704a97a05"
      },
      "source": [
        "# figure out which feature is of the most importance\r\n",
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels\r\n",
        "w = model.fit(X,y,learning_rate=0.001)\r\n",
        "print(w)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early stop at iteration:  2408\n",
            "[[ 1.55081845]\n",
            " [ 1.0933058 ]\n",
            " [-4.03375893]\n",
            " [ 1.94595797]\n",
            " [ 1.26066542]\n",
            " [-1.71833441]\n",
            " [-0.70288352]\n",
            " [-2.77580802]\n",
            " [-0.22065837]\n",
            " [-2.45386379]\n",
            " [ 0.14203829]\n",
            " [-4.5782209 ]\n",
            " [-0.14985273]\n",
            " [-1.1939046 ]\n",
            " [-0.61306626]\n",
            " [-0.16584005]\n",
            " [ 1.27379042]\n",
            " [ 1.29107767]\n",
            " [-0.01049958]\n",
            " [-1.0596618 ]\n",
            " [-0.4266146 ]\n",
            " [ 1.70847384]\n",
            " [ 0.45035064]\n",
            " [-0.41407882]\n",
            " [-0.48774679]\n",
            " [ 0.1353532 ]\n",
            " [-0.91413545]\n",
            " [ 0.12909789]\n",
            " [ 1.2530027 ]\n",
            " [ 4.96807387]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accu_trains = []\n",
        "    accu_tests = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      model = Logistic_regression()\n",
        "      w = model.fit(X_train, y_train, lr)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "\n",
        "      print(\"----Train----\")\n",
        "      y_predict_train = model.predict(w, X_train)\n",
        "      accu_train = model.Accu_eval(y_train, y_predict_train)\n",
        "      accu_trains.append(accu_train)\n",
        "\n",
        "      print(\"----Validation----\")\n",
        "      y_predict_test = model.predict(w, X_test)\n",
        "      accu_test = model.Accu_eval(y_test, y_predict_test)\n",
        "      accu_tests.append(accu_test)\n",
        "\n",
        "    return np.mean(accu_trains), np.mean(accu_tests)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKbtaUO53F00",
        "outputId": "ab98478f-03aa-4f36-dd7f-8dbaaacefaf2"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(original_data)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9292929292929293\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8856502242152466\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8329596412556054\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8609865470852018\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8374439461883408\n",
            "----Validation----\n",
            "accuracy: 0.7676767676767676\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9383408071748879\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8688340807174888\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8941624767857952 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8879494949494949 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9281705948372615\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8408071748878924\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8251121076233184\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9316143497757847\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8553811659192825\n",
            "----Validation----\n",
            "accuracy: 0.8484848484848485\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8419282511210763\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8239910313901345\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8699551569506726\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8307174887892377\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "---------------TRAIN AVERAGE ACCURACY 0.867480736613771 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8556262626262626 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8518518518518519\n",
            "----Validation----\n",
            "accuracy: 0.87\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8374439461883408\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8822869955156951\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8576233183856502\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8363228699551569\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8452914798206278\n",
            "----Validation----\n",
            "accuracy: 0.8686868686868687\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8688340807174888\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8767771134363063 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8758888888888888 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8518518518518519\n",
            "----Validation----\n",
            "accuracy: 0.87\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8239910313901345\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8665919282511211\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8576233183856502\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8385650224215246\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9204035874439462\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8873152300282345 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8829595959595959 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248035914702581\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8643497757847534\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8385650224215246\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.92152466367713\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "---------------TRAIN AVERAGE ACCURACY 0.911426547487833 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9031010101010102 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9259259259259259\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8789237668161435\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8632286995515696\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8565022421524664\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.820627802690583\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8665919282511211\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "---------------TRAIN AVERAGE ACCURACY 0.892704700215911 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.893 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8518518518518519\n",
            "----Validation----\n",
            "accuracy: 0.87\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8352017937219731\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8811659192825112\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8262331838565022\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8385650224215246\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.874439461883408\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8307174887892377\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8722928085035708 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8718484848484849 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8518518518518519\n",
            "----Validation----\n",
            "accuracy: 0.87\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8822869955156951\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8632286995515696\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8565022421524664\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8665919282511211\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8969564856336157 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.899121212121212 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8518518518518519\n",
            "----Validation----\n",
            "accuracy: 0.87\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8374439461883408\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8239910313901345\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9271300448430493\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8385650224215246\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.820627802690583\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8665919282511211\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8307174887892377\n",
            "----Validation----\n",
            "accuracy: 0.8383838383838383\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8647815977412391 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8546767676767677 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9259259259259259\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8789237668161435\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8553811659192825\n",
            "----Validation----\n",
            "accuracy: 0.8181818181818182\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8363228699551569\n",
            "----Validation----\n",
            "accuracy: 0.7777777777777778\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9204035874439462\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9064939378840725 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9020909090909092 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd04abf-9aef-420b-b5f7-9e7afe6bdd63"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "Early stop at iteration:  1526\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.8877665544332211\n",
            "----Validation----\n",
            "accuracy: 0.85\n",
            "Early stop at iteration:  1513\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1481\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.8890134529147982\n",
            "----Validation----\n",
            "accuracy: 0.8282828282828283\n",
            "Early stop at iteration:  1589\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.8946188340807175\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1536\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.8968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.8585858585858586\n",
            "Early stop at iteration:  1482\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.8923766816143498\n",
            "----Validation----\n",
            "accuracy: 0.8080808080808081\n",
            "Early stop at iteration:  1535\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.8912556053811659\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1581\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.8878923766816144\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1523\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.8845291479820628\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1524\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.8878923766816144\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "---------------TRAIN AVERAGE ACCURACY 0.8901219469231428 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.8839898989898989 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "Early stop at iteration:  1431\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.936026936026936\n",
            "----Validation----\n",
            "accuracy: 0.9\n",
            "Early stop at iteration:  1491\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9248878923766816\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1437\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9394618834080718\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1448\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9327354260089686\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1362\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "Early stop at iteration:  1455\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9338565022421524\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1425\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9349775784753364\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  1452\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1483\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1451\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9282511210762332\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9322798236475366 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9263636363636364 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "Early stop at iteration:  1753\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9539842873176206\n",
            "----Validation----\n",
            "accuracy: 0.91\n",
            "Early stop at iteration:  1843\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1713\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "Early stop at iteration:  1847\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1789\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1797\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  1879\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1733\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  1764\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1876\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9527975318707755 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9445353535353535 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "Early stop at iteration:  2404\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9640852974186308\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2484\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "Early stop at iteration:  2182\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2467\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2518\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2432\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  2521\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2450\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2434\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2580\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9633367808629393 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9545959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "Early stop at iteration:  2653\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663299663299664\n",
            "----Validation----\n",
            "accuracy: 0.96\n",
            "Early stop at iteration:  2617\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2397\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2765\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2937\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2538\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2681\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2724\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2592\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2886\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9656912925971222 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9576161616161617 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "Early stop at iteration:  2533\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2171\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2071\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "Early stop at iteration:  2383\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2503\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2211\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2298\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2368\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  2247\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2940\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9671488175225097 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9545959595959597 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "Early stop at iteration:  2210\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  1754\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1711\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1902\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2089\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  2072\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2034\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  1939\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1884\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2659\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9675972480157832 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9556060606060607 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "Early stop at iteration:  2825\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674523007856342\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "Early stop at iteration:  2045\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1701\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1587\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2368\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9697309417040358\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "Early stop at iteration:  3672\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2748\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "Early stop at iteration:  2094\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  1989\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3424\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9677093556391017 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9566161616161615 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506172839506173\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.945067264573991\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9505550019376626 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9414949494949495 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9270482603815937\n",
            "----Validation----\n",
            "accuracy: 0.9\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9405829596412556\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9394618834080718\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9492070681906257 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9455555555555556 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tX0BHqIfsy"
      },
      "source": [
        "## Experiment with different features\n",
        "\n",
        "During the experiment on different learning rates, we found that the best learning rate is **0.0046**, so we use this learning rate for our experiment with different feature selections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02227b0f-7b36-473f-ffa6-1dfe6f014192"
      },
      "source": [
        "lr = 0.0046\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n",
            "Early stop at iteration:  1825\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652076318742986\n",
            "----Validation----\n",
            "accuracy: 0.97\n",
            "Early stop at iteration:  2025\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9719730941704036\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2063\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1911\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2023\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  1928\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  1787\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  2032\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2714\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9708520179372198\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "Early stop at iteration:  1719\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------AVERAGE ACCURACY: train- 0.9673727811246497  vs. validation- 0.9576060606060606 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e7907d-027f-478f-c9f8-457b119889bc"
      },
      "source": [
        "lr = 0.0046\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "Early stop at iteration:  2983\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9764309764309764\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "Early stop at iteration:  2488\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9674887892376681\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  3218\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "Early stop at iteration:  3961\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2726\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  4297\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9730941704035875\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "Early stop at iteration:  4065\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "Early stop at iteration:  2685\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3701\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9663677130044843\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "Early stop at iteration:  3074\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------AVERAGE ACCURACY: train- 0.9675982545937704  vs. validation- 0.9556262626262626 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSYRgbudHMP"
      },
      "source": [
        "## Measure the run time\n",
        "See whether the model converges faster on normalized data than on original data. This is measured by training the model and time it. This part stands on its own, and is not related to any of the above process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrGEPixJmmcc"
      },
      "source": [
        "This model class is almost the same as the one before. The only difference is that this model **does not have early stopping**, which can interfere with our timing. Also, this model is only for timing the training process, so it only has a 'fit' method\n",
        "\n",
        "**Should we run this? Should we have early stopping or not?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhONMhAxkuC7"
      },
      "source": [
        "###Comparison on Original dataset and normalized dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T-jHRpsdgHZ"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(original_data)\n",
        "X = original_data[:, :-1]  # features\n",
        "y = original_data[:, -1]   # labels"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ39ltUkkZJj",
        "outputId": "d4ddf923-da1a-4f15-adea-3f08fbab3141"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 34.3 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0btaceUVd83p"
      },
      "source": [
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oePKiDuLlyNs",
        "outputId": "363f06bb-4248-434a-e36d-9f738b3e2db2"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 32.9 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCwwb-clC5m"
      },
      "source": [
        "###Using normalized features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOcmreeith4"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tP6ejB1go3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1fcd15-52f9-4580-b732-a36901fd890e"
      },
      "source": [
        "import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "lr = [1]\r\n",
        "t = []\r\n",
        "for index in range(10):\r\n",
        "  lr.append(lr[-1]*0.1)\r\n",
        "  t1 = time.time()\r\n",
        "  model.fit(X, y, learning_rate=lr[-1])\r\n",
        "  t2 = time.time()\r\n",
        "  print(\"lr: \",lr[-1],\"time: \", t2-t1)\r\n",
        "  t.append(t2-t1)\r\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr:  0.1 time:  0.03873467445373535\n",
            "lr:  0.010000000000000002 time:  0.03523588180541992\n",
            "lr:  0.0010000000000000002 time:  0.03632068634033203\n",
            "lr:  0.00010000000000000003 time:  0.03643393516540527\n",
            "lr:  1.0000000000000004e-05 time:  0.03739666938781738\n",
            "lr:  1.0000000000000004e-06 time:  0.035956382751464844\n",
            "Early stop at iteration:  1\n",
            "lr:  1.0000000000000005e-07 time:  0.0011954307556152344\n",
            "Early stop at iteration:  1\n",
            "lr:  1.0000000000000005e-08 time:  0.0013427734375\n",
            "Early stop at iteration:  1\n",
            "lr:  1.0000000000000005e-09 time:  0.00048041343688964844\n",
            "Early stop at iteration:  1\n",
            "lr:  1.0000000000000006e-10 time:  0.0005207061767578125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsBmIGxghil3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "cd604ea0-0f6b-4603-e238-940423680fff"
      },
      "source": [
        "plt.plot(lr[1:],t)\r\n",
        "plt.xscale('log')\r\n",
        "plt.yscale('log')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTl5SSvzSR8p"
      },
      "source": [
        "## Scanning more lrs, in order to find the relation between lr and time for convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKC_xyrBEdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "522d6da9-594a-472e-b5a5-4c7e0734486c"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels\n",
        "\n",
        "lrs = np.logspace(-4, -1, 20) # different learning rates to try\n",
        "times = []\n",
        "\n",
        "for lr in lrs:\n",
        "  model = Logistic_regression()\n",
        "  print(\"learning rate: \", lr)\n",
        "  t1 = time.time()\n",
        "  w = model.fit(X, y, learning_rate=lr)\n",
        "  t2 = time.time()\n",
        "  print(\"time: \", t2-t1)\n",
        "  times.append(t2-t1)\n",
        "\n",
        "plt.plot(times)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate:  0.0001\n",
            "Early stop at iteration:  2012\n",
            "time:  0.16866469383239746\n",
            "learning rate:  0.0001438449888287663\n",
            "Early stop at iteration:  2245\n",
            "time:  0.16928339004516602\n",
            "learning rate:  0.00020691380811147902\n",
            "Early stop at iteration:  2466\n",
            "time:  0.17593979835510254\n",
            "learning rate:  0.00029763514416313193\n",
            "Early stop at iteration:  2631\n",
            "time:  0.20833754539489746\n",
            "learning rate:  0.00042813323987193956\n",
            "Early stop at iteration:  2655\n",
            "time:  0.1932048797607422\n",
            "learning rate:  0.0006158482110660267\n",
            "Early stop at iteration:  2568\n",
            "time:  0.21102690696716309\n",
            "learning rate:  0.0008858667904100823\n",
            "Early stop at iteration:  2450\n",
            "time:  0.17781496047973633\n",
            "learning rate:  0.0012742749857031334\n",
            "Early stop at iteration:  2320\n",
            "time:  0.17957282066345215\n",
            "learning rate:  0.0018329807108324356\n",
            "Early stop at iteration:  2180\n",
            "time:  0.1585526466369629\n",
            "learning rate:  0.0026366508987303583\n",
            "Early stop at iteration:  2041\n",
            "time:  0.15771889686584473\n",
            "learning rate:  0.00379269019073225\n",
            "Early stop at iteration:  1925\n",
            "time:  0.14241695404052734\n",
            "learning rate:  0.005455594781168515\n",
            "Early stop at iteration:  1885\n",
            "time:  0.15503621101379395\n",
            "learning rate:  0.007847599703514606\n",
            "Early stop at iteration:  1985\n",
            "time:  0.1417686939239502\n",
            "learning rate:  0.011288378916846883\n",
            "Early stop at iteration:  2168\n",
            "time:  0.1696460247039795\n",
            "learning rate:  0.01623776739188721\n",
            "time:  0.36074018478393555\n",
            "learning rate:  0.023357214690901212\n",
            "time:  0.38730502128601074\n",
            "learning rate:  0.03359818286283781\n",
            "time:  0.3758578300476074\n",
            "learning rate:  0.04832930238571752\n",
            "time:  0.37659144401550293\n",
            "learning rate:  0.06951927961775606\n",
            "time:  0.3914351463317871\n",
            "learning rate:  0.1\n",
            "time:  0.36919236183166504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f93239f8be0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}