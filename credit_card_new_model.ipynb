{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit_card_exp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/Try-colabing-in-colab/blob/main/credit_card_new_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NkwhApnnJk"
      },
      "source": [
        "# ECSE 551 Mini-project 1\n",
        "*Group 10: Junhao Wang, Yinan Zhou, and Ruilin Ji*\n",
        "\n",
        "This notebook is dedicated for the credit card dataset, including the model, cross validation, and various experiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeEmvASNOp83"
      },
      "source": [
        "## Start here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGuRPcn_IsKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671d1c8d-07d7-4589-dc0a-c0f787c7a960"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrLPT4OTIt5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3854fe09-0aaf-4bad-97fa-4c83a194f56d"
      },
      "source": [
        "%cd \"/content/drive/My Drive/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNizIZXIrdM"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import scipy.stats\r\n",
        "import statistics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_w-5Z0sMsJ"
      },
      "source": [
        "## Credit Card Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-nyMGN0pKx"
      },
      "source": [
        "# generate new feature by multiplication and normalize\r\n",
        "def newfeature(x,y):\r\n",
        "  z=x*y\r\n",
        "  norz=scipy.stats.zscore(z, axis=0, ddof=0, nan_policy='propagate')\r\n",
        "  return norz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXiM3pnF5j-2"
      },
      "source": [
        "# convert csv to dataframe\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "original_data = df.to_numpy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHo1NiB4xWr"
      },
      "source": [
        "# normalize feature\r\n",
        "NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate') # no class column\r\n",
        "# normalized dataset\r\n",
        "NorDataset = np.column_stack((NorData,df.iloc[:,-1]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kzCB3F5uWL"
      },
      "source": [
        "New feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyg90-iG5vCB"
      },
      "source": [
        "NewF1 = newfeature(df.V3, df.V7)\r\n",
        "NewF2 = newfeature(df.V11, df.V12)\r\n",
        "NewF3 = newfeature(df.V12, df.V16)\r\n",
        "NewF4 = newfeature(df.V16, df.V17)\r\n",
        "NewF5 = newfeature(df.V16, df.V18)\r\n",
        "NewF6 = newfeature(df.V17, df.V18)\r\n",
        "NewF7 = df.iloc[:,0]              # initialize new feature 7 using 1st feature\r\n",
        "n_row,n_col = np.shape(NorData)\r\n",
        "NewFSq = np.zeros(n_row)            # initialize new features using 0s\r\n",
        "for col in range(n_col):\r\n",
        "  # new feature 7: multiplying all features\r\n",
        "  if col>0:\r\n",
        "    NewF7 = newfeature(NewF7,df.iloc[:,col])\r\n",
        "  # new feature 8-: square all columns\r\n",
        "  new = newfeature(df.iloc[:,col],df.iloc[:,col]) # square feature\r\n",
        "  NewFSq = np.column_stack((NewFSq,new))\r\n",
        "\r\n",
        "NewFSq = np.delete(NewFSq,0,1)\r\n",
        "# new feature\r\n",
        "NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6,NewF7))\r\n",
        "# NewF = np.column_stack((NewF1,NewF2,NewF3,NewF4,NewF5,NewF6))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMYL_506R_G"
      },
      "source": [
        "# normalized dataset with new feature\r\n",
        "NorDatasetNew = np.column_stack((NorData,NewF,df.iloc[:,-1]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnmcLuQsdWb"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1X71amBOCtA"
      },
      "source": [
        "'''# sigmoid function\n",
        "def sigmoid(a):\n",
        "  # to avoid overflow in exp\n",
        "  if -a > np.log(np.finfo(type(a)).max):\n",
        "    return 0.0  \n",
        "  return 1/(1+np.exp(-a))'''\n",
        "  \n",
        "# sigmoid function\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "\n",
        "\n",
        "class Logistic_regression():\n",
        "  def __init__(self):#,X_train,y_train,learning_rate,X_test,y_test):\n",
        "    pass\n",
        "    \n",
        "  # training\n",
        "  def fit(self,X_train,y_train,learning_rate):\n",
        "    #n,m = np.shape(self.X_train)\n",
        "    n,m = np.shape(X_train)  \n",
        "    wk = np.ones([m+1,1]) # wk weights, initialized with 1\n",
        "    wk1 = np.zeros([m+1,1])# wk+1 weights,initialized with 0          \n",
        "    itrnum = 500       # max number of iterations \n",
        "    e = 0.001\n",
        "    der = 0\n",
        "    for k in range(0,itrnum):\n",
        "      for i in range(0,n):\n",
        "        #xi = self.X_train[i].T\n",
        "        xi = X_train[i].T\n",
        "        x0 = np.array([1])\n",
        "        xi = np.concatenate((xi, x0),axis = 0)\n",
        "        #yi = self.y_train[i]\n",
        "        yi = y_train[i]\n",
        "        der = der-xi*(yi-sigmoid(np.matmul(wk[:,0].T,xi))) # take derivative w.r.t w\n",
        "      #wk1[:,0] = wk[:,0]-self.learning_rate*der       # update rule\n",
        "      wk1[:,0] = wk[:,0]-learning_rate*der       # update rule\n",
        "      if (np.linalg.norm(wk1[:,0]-wk[:,0]))**2<e:\n",
        "        # print(\"Training stoppped early at iteration: \", k+1)      \n",
        "        break \n",
        "      else:\n",
        "        wk = wk1.copy()\n",
        "    return wk1\n",
        "  \n",
        "  # validation\n",
        "  def predict(self,w,X_test):\n",
        "    #n,m = np.shape(self.X_test)\n",
        "    n,m = np.shape(X_test)   \n",
        "    y_predict = np.zeros([n,1])\n",
        "    for i in range(0,n):\n",
        "      #xi = self.X_test[i].T\n",
        "      xi = X_test[i].T\n",
        "      x0 = np.array([1])\n",
        "      xi = np.concatenate((xi, x0),axis = 0)\n",
        "      p1 = sigmoid(np.matmul(w.T,xi)) # calculate probabilities p(y=1|x)\n",
        "      # covert probabilities to 0 or 1 by thresholding at 0.5\n",
        "      if p1>=0.5:\n",
        "        y_predict[i] = 1\n",
        "      else:\n",
        "        y_predict[i] = 0\n",
        "    return y_predict\n",
        "\n",
        "  # evaluate accuracy\n",
        "  def Accu_eval(self,y_test,y_predict):\n",
        "    #y_predict = self.predict(X_test)\n",
        "    n,j = np.shape(y_predict)\n",
        "    TP = 0;FP = 0;TN = 0;FN = 0\n",
        "    # count TP,TN,FP,FN in validation set\n",
        "    '''for i in range(n):\n",
        "      if  self.y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif self.y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif self.y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1'''\n",
        "    for i in range(n):\n",
        "      if  y_test[i]==1 and y_predict[i]==1:\n",
        "        TP = TP+1\n",
        "      elif y_test[i]==0 and y_predict[i]==0:\n",
        "        TN = TN+1\n",
        "      elif y_test[i]==0 and y_predict[i]==1:\n",
        "        FP = FP+1\n",
        "      elif y_test[i]==1 and y_predict[i]==0:\n",
        "        FN = FN+1    \n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    F = 2*precision*recall/(precision+recall)\n",
        "    specificity = TN/(FP+TN)\n",
        "    FPR = FP/(FP+TN)\n",
        "    print(\"accuracy:\",accuracy)\n",
        "    # print(\"precision:\",precision)\n",
        "    # print(\"recall:\",recall)\n",
        "    # print(\"F:\",F)\n",
        "    # print(\"specificity:\",specificity)\n",
        "    # print(\"False Positive Rate:\",FPR)\n",
        "    # print(\"\")\n",
        "    return accuracy\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ43SMNlZwiV",
        "outputId": "12021802-b673-411c-888a-cb5a5a5ac48f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# figure out which feature is of the most importance\r\n",
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels\r\n",
        "w = model.fit(X,y,learning_rate=0.001)\r\n",
        "print(w)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 122.47084445]\n",
            " [  94.7390446 ]\n",
            " [-405.51387301]\n",
            " [ 102.67860117]\n",
            " [  13.47884961]\n",
            " [-143.36283177]\n",
            " [ -81.09335631]\n",
            " [-226.8244388 ]\n",
            " [  16.01617032]\n",
            " [-223.52979084]\n",
            " [ -48.22147504]\n",
            " [-288.9874883 ]\n",
            " [   0.51483489]\n",
            " [ -49.17560667]\n",
            " [ -53.35039804]\n",
            " [ -58.57067771]\n",
            " [  92.42418619]\n",
            " [  12.60089495]\n",
            " [   1.10465039]\n",
            " [ -75.43775535]\n",
            " [ -57.55455013]\n",
            " [ 133.56584277]\n",
            " [  29.24635998]\n",
            " [ -49.15440343]\n",
            " [ -37.6098162 ]\n",
            " [   3.37297339]\n",
            " [ -68.78216283]\n",
            " [ -24.24531042]\n",
            " [  88.69034165]\n",
            " [ 500.17398059]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAaqa2lsZhe"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmGiMSZ7wqx"
      },
      "source": [
        "class Cross_validation():\n",
        "  def __init__(self, k):\n",
        "    # k: k-fold\n",
        "    self.k = k\n",
        "\n",
        "  def prepare_data(self, data):\n",
        "    # data: np array converted from csv\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :-1]  # features\n",
        "    y = data[:, -1]   # labels\n",
        "\n",
        "    # split data into k equal segments, assign them to train and test later\n",
        "    Xs = np.array_split(X, self.k, axis=0)\n",
        "    ys = np.array_split(y, self.k, axis=0)\n",
        "    return Xs, ys\n",
        "\n",
        "  def get_accuracy(self, Xs, ys, lr):\n",
        "    accu_trains = []\n",
        "    accu_tests = []\n",
        "    for i in range(self.k):\n",
        "      X_cv = Xs[:] # X_cross_validation\n",
        "      y_cv = ys[:] # y_cross_validation\n",
        "\n",
        "      X_test = X_cv.pop(i)\n",
        "      y_test = y_cv.pop(i)\n",
        "\n",
        "      X_train = np.concatenate(X_cv)\n",
        "      y_train = np.concatenate(y_cv)\n",
        "\n",
        "      model = Logistic_regression()\n",
        "      w = model.fit(X_train, y_train, lr)\n",
        "\n",
        "      print(\"----------FOLD \", i+1, \"----------\")\n",
        "\n",
        "      print(\"----Train----\")\n",
        "      y_predict_train = model.predict(w, X_train)\n",
        "      accu_train = model.Accu_eval(y_train, y_predict_train)\n",
        "      accu_trains.append(accu_train)\n",
        "\n",
        "      print(\"----Validation----\")\n",
        "      y_predict_test = model.predict(w, X_test)\n",
        "      accu_test = model.Accu_eval(y_test, y_predict_test)\n",
        "      accu_tests.append(accu_test)\n",
        "\n",
        "    return np.mean(accu_trains), np.mean(accu_tests)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8uhC3hsReE"
      },
      "source": [
        "## Experiment with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcQFygT8GOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31040b68-3cd8-4799-eef6-377de0c13f8e"
      },
      "source": [
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "# or we can also try other hyperparameters here\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "for lr in lrs:\n",
        "  print(\"---------------LEARNING RATE: \", lr, \"---------------\")\n",
        "  accu_train_avg, accu_val_avg = cv.get_accuracy(Xs, ys, lr)\n",
        "  print(\"---------------TRAIN AVERAGE ACCURACY\", accu_train_avg, \"---------------\")\n",
        "  print(\"---------------VALIDATION AVERAGE ACCURACY\", accu_val_avg, \"---------------\")\n",
        "  print(\"\\n-------------------------------------------------------------------------------\\n\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------LEARNING RATE:  1e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.24803591470258138\n",
            "----Validation----\n",
            "accuracy: 0.23\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.24551569506726456\n",
            "----Validation----\n",
            "accuracy: 0.25252525252525254\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.24551569506726456\n",
            "----Validation----\n",
            "accuracy: 0.25252525252525254\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.25\n",
            "----Validation----\n",
            "accuracy: 0.21212121212121213\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.24103139013452915\n",
            "----Validation----\n",
            "accuracy: 0.29292929292929293\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.24439461883408073\n",
            "----Validation----\n",
            "accuracy: 0.26262626262626265\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.242152466367713\n",
            "----Validation----\n",
            "accuracy: 0.2828282828282828\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.25448430493273544\n",
            "----Validation----\n",
            "accuracy: 0.1717171717171717\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.24439461883408073\n",
            "----Validation----\n",
            "accuracy: 0.26262626262626265\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.24663677130044842\n",
            "----Validation----\n",
            "accuracy: 0.24242424242424243\n",
            "---------------TRAIN AVERAGE ACCURACY 0.24621614752406978 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.24623232323232322 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  2.782559402207126e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9225589225589226\n",
            "----Validation----\n",
            "accuracy: 0.87\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.922645739910314\n",
            "----Validation----\n",
            "accuracy: 0.8787878787878788\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9170403587443946\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9181614349775785\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9304932735426009\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9327354260089686\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.929372197309417\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9159192825112108\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9136771300448431\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9192825112107623\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9221886276819011 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9152828282828283 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  7.742636826811278e-05 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9584736251402918\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9567218019759126 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9515757575757577 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.00021544346900318823 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618406285072951\n",
            "----Validation----\n",
            "accuracy: 0.93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9576190404292049 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9445151515151515 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0005994842503189409 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9584736251402918\n",
            "----Validation----\n",
            "accuracy: 0.92\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9572823400925046 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9404848484848485 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.0016681005372000592 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9584736251402918\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9581792010790517 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9424848484848486 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.004641588833612777 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618406285072951\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9585201793721974\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9536952736130612 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9465252525252523 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.012915496650148827 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9629629629629629\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9484304932735426\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.8888888888888888\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9540358744394619\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9533590765653546 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9424747474747475 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.03593813663804626 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652076318742986\n",
            "----Validation----\n",
            "accuracy: 0.94\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.98989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.952914798206278\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9652466367713004\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9531351129632146 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9404646464646464 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "---------------LEARNING RATE:  0.1 ---------------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9629629629629629\n",
            "----Validation----\n",
            "accuracy: 0.95\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9428251121076233\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9461883408071748\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9517937219730942\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9506726457399103\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9517937219730942\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "---------------TRAIN AVERAGE ACCURACY 0.9515653545922605 ---------------\n",
            "---------------VALIDATION AVERAGE ACCURACY 0.9404545454545454 ---------------\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tX0BHqIfsy"
      },
      "source": [
        "## Experiment with different features\n",
        "\n",
        "During the experiment on different learning rates, we found that the best learning rate is **0.0002154**, so we use this learning rate for our experiment with different feature selections. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPPRiALdIj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7f0cbe-49cd-4982-ef97-f97464af1343"
      },
      "source": [
        "lr = 0.0002154\n",
        "cv = Cross_validation(10) # 10-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDataset)\n",
        "print(\"----------Using normalized features, without new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, without new features----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9528619528619529\n",
            "----Validation----\n",
            "accuracy: 0.93\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9641255605381166\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9573991031390134\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9495515695067265\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9473094170403588\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9191919191919192\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------AVERAGE ACCURACY: train- 0.9566090652413521  vs. validation- 0.9435050505050505 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5HstgXSJ8rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5054bded-aaf7-4ff4-e467-70e36b03f284"
      },
      "source": [
        "lr = 0.0002154\n",
        "cv = Cross_validation(10) # 5-fold cross-validation\n",
        "Xs, ys = cv.prepare_data(NorDatasetNew)\n",
        "print(\"----------Using normalized features, with new features----------\")\n",
        "accu_avg_train, accu_avg_val = cv.get_accuracy(Xs, ys, lr)\n",
        "print(\"----------AVERAGE ACCURACY: train-\",accu_avg_train,\" vs. validation-\",accu_avg_val, \"----------\")\n",
        "print(\"\\n---------------------------------------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Using normalized features, with new features----------\n",
            "----------FOLD  1 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562289562289562\n",
            "----Validation----\n",
            "accuracy: 0.97\n",
            "----------FOLD  2 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  3 ----------\n",
            "----Train----\n",
            "accuracy: 0.9596412556053812\n",
            "----Validation----\n",
            "accuracy: 0.898989898989899\n",
            "----------FOLD  4 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9292929292929293\n",
            "----------FOLD  5 ----------\n",
            "----Train----\n",
            "accuracy: 0.9630044843049327\n",
            "----Validation----\n",
            "accuracy: 0.9393939393939394\n",
            "----------FOLD  6 ----------\n",
            "----Train----\n",
            "accuracy: 0.9618834080717489\n",
            "----Validation----\n",
            "accuracy: 0.9696969696969697\n",
            "----------FOLD  7 ----------\n",
            "----Train----\n",
            "accuracy: 0.9562780269058296\n",
            "----Validation----\n",
            "accuracy: 0.9494949494949495\n",
            "----------FOLD  8 ----------\n",
            "----Train----\n",
            "accuracy: 0.9607623318385651\n",
            "----Validation----\n",
            "accuracy: 0.9595959595959596\n",
            "----------FOLD  9 ----------\n",
            "----Train----\n",
            "accuracy: 0.9551569506726457\n",
            "----Validation----\n",
            "accuracy: 0.9797979797979798\n",
            "----------FOLD  10 ----------\n",
            "----Train----\n",
            "accuracy: 0.968609865470852\n",
            "----Validation----\n",
            "accuracy: 0.9090909090909091\n",
            "----------AVERAGE ACCURACY: train- 0.9603089942776041  vs. validation- 0.9485151515151514 ----------\n",
            "\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jSYRgbudHMP"
      },
      "source": [
        "## Measure the run time\n",
        "See whether the model converges faster on normalized data than on original data. This is measured by training the model and time it. This part stands on its own, and is not related to any of the above process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrGEPixJmmcc"
      },
      "source": [
        "This model class is almost the same as the one before. The only difference is that this model **does not have early stopping**, which can interfere with our timing. Also, this model is only for timing the training process, so it only has a 'fit' method\n",
        "\n",
        "**Should we run this? Should we have early stopping or not?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhONMhAxkuC7"
      },
      "source": [
        "###Comparison on Original dataset and normalized dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T-jHRpsdgHZ"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(original_data)\n",
        "X = original_data[:, :-1]  # features\n",
        "y = original_data[:, -1]   # labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ39ltUkkZJj",
        "outputId": "b0c9657e-8754-4bf0-d041-e38e4ba77235"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 6.79 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0btaceUVd83p"
      },
      "source": [
        "model = Logistic_regression()\r\n",
        "np.random.shuffle(NorDataset)\r\n",
        "X = NorDataset[:, :-1]  # features\r\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oePKiDuLlyNs",
        "outputId": "44066e42-b69e-4c73-f5cc-3e25be2124ea"
      },
      "source": [
        "%%timeit\n",
        "w = model.fit(X, y, learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 6.11 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aCwwb-clC5m"
      },
      "source": [
        "###Using normalized features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOcmreeith4"
      },
      "source": [
        "model = Logistic_regression()\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tP6ejB1go3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea13acb-67f7-4b87-ca45-f08ed900ba11"
      },
      "source": [
        "import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "lr = [1]\r\n",
        "t = []\r\n",
        "for index in range(10):\r\n",
        "  lr.append(lr[-1]*0.1)\r\n",
        "  t1 = time.time()\r\n",
        "  model.fit(X, y, learning_rate=lr[-1])\r\n",
        "  t2 = time.time()\r\n",
        "  print(\"lr: \",lr[-1],\"time: \", t2-t1)\r\n",
        "  t.append(t2-t1)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lr:  0.1 time:  7.110478639602661\n",
            "lr:  0.010000000000000002 time:  6.729063510894775\n",
            "lr:  0.0010000000000000002 time:  6.268208026885986\n",
            "lr:  0.00010000000000000003 time:  6.1151816844940186\n",
            "lr:  1.0000000000000004e-05 time:  0.011788129806518555\n",
            "lr:  1.0000000000000004e-06 time:  0.011670827865600586\n",
            "lr:  1.0000000000000005e-07 time:  0.01789093017578125\n",
            "lr:  1.0000000000000005e-08 time:  0.017074108123779297\n",
            "lr:  1.0000000000000005e-09 time:  0.02828073501586914\n",
            "lr:  1.0000000000000006e-10 time:  0.027080297470092773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsBmIGxghil3"
      },
      "source": [
        "plt.plot(lr[1:],t)\r\n",
        "plt.xscale('log')\r\n",
        "plt.yscale('log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTl5SSvzSR8p"
      },
      "source": [
        "## Scanning more lrs, in order to find the relation between lr and time for convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKC_xyrBEdH"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# df = pd.read_csv('creditcard.csv')\n",
        "# data = df.to_numpy()\n",
        "\n",
        "# # normalize feature\n",
        "# NorData = scipy.stats.zscore(df.iloc[:,:-1], axis=0, ddof=0, nan_policy='propagate') # no class column\n",
        "# # normalized dataset\n",
        "# NorDataset = np.column_stack((NorData,df.iloc[:,-1]))\n",
        "\n",
        "np.random.shuffle(NorDataset)\n",
        "X = NorDataset[:, :-1]  # features\n",
        "y = NorDataset[:, -1]   # labels\n",
        "\n",
        "lrs = np.logspace(-5, -1, 10) # different learning rates to try\n",
        "times = []\n",
        "\n",
        "for lr in lrs:\n",
        "  model = Logistic_regression()\n",
        "  print(\"learning rate: \", lr)\n",
        "  t1 = time.time()\n",
        "  w = model.fit(X, y, learning_rate=lr)\n",
        "  t2 = time.time()\n",
        "  print(\"time: \", t2-t1)\n",
        "  times.append(t2-t1)\n",
        "\n",
        "plt.plot(times)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}